{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpKXtISNidUo",
        "outputId": "d5758f04-47ac-49d7-bce6-106229cd2a54"
      },
      "source": [
        "from collections import OrderedDict\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 전처리\n",
        "def preprocess(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('.', ' .')\n",
        "  words = text.split(' ')\n",
        "\n",
        "  word_to_id = {}\n",
        "  id_to_word = {}\n",
        "\n",
        "  for word in words:\n",
        "    if word not in word_to_id:\n",
        "      new_id = len(word_to_id)\n",
        "      word_to_id[word] = new_id\n",
        "      id_to_word[new_id] = word\n",
        "\n",
        "  corpus = np.array([word_to_id[x] for x in words])\n",
        "  return corpus, word_to_id, id_to_word\n",
        "\n",
        "text = 'you say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "\n",
        "print(corpus)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 1 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CDm-F95MU-R"
      },
      "source": [
        "### 동시발생 행렬\n",
        "동시발행 행렬은 단어를 벡터로 표현하기 위한 첫번째 시도이다.\n",
        "단어의 의미는 주변 단어에 의해 형성된다는 '분포 가설(distributional hypothesis)'에 기초하여 만들어진 기법이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrcgFqRYL4k-",
        "outputId": "d68275ce-7739-4137-88d1-006029cbf892"
      },
      "source": [
        "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
        "  corpus_size = len(corpus)\n",
        "  co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
        "\n",
        "  for idx, word_id in enumerate(corpus):\n",
        "    for i in range(1, window_size + 1):\n",
        "      left_idx = idx - i\n",
        "      right_idx = idx + i\n",
        "\n",
        "      if left_idx >= 0:\n",
        "        left_word_id = corpus[left_idx]\n",
        "        co_matrix[word_id, left_word_id] += 1\n",
        "\n",
        "      if right_idx < corpus_size:\n",
        "        right_word_id = corpus[right_idx]\n",
        "        co_matrix[word_id, right_word_id] += 1\n",
        "      \n",
        "  return co_matrix\n",
        "\n",
        "C = create_co_matrix(corpus, len(word_to_id))\n",
        "print(C)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 0 0 0 0]\n",
            " [1 0 1 0 1 1 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 0 1 0 1 0 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSpJZ_LxMsZx"
      },
      "source": [
        "### 코사인 유사도(cosine similarity)\n",
        "\n",
        "코사인 유사도는 벡터 간 유사도를 구하는 가장 대표적인 기법이다.\n",
        "이는 직관적으로 해석하자면, 두 벡터가 가리키는 방향의 코사인 값을 구하는 것이다.\n",
        "두 벡터 사이의 각도가 작을 수록 값이 커진다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_diNcOhSMsD1",
        "outputId": "0f7d76d7-d9e9-45bc-cd46-b6484f38804a"
      },
      "source": [
        "def cos_similarity(x, y, eps=1e-8):\n",
        "  nx = x / np.sqrt(np.sum(x**2) + eps)\n",
        "  ny = y / np.sqrt(np.sum(y**2) + eps)\n",
        "  return np.dot(nx, ny)\n",
        "\n",
        "c0 = C[word_to_id['you']]\n",
        "c1 = C[word_to_id['i']]\n",
        "print(cos_similarity(c0, c1))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7071067758832467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFjVVZQGOYzz"
      },
      "source": [
        "### 유사 단어의 랭킹 표시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxccY008OcgG",
        "outputId": "3924df41-f853-41fd-f03d-a2a5abcf7afa"
      },
      "source": [
        "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
        "  if query not in word_to_id:\n",
        "    print('%s을 찾을 수 없습니다.' % query)\n",
        "    return\n",
        "  \n",
        "  print('\\n[query] ' + query)\n",
        "  query_id = word_to_id[query]\n",
        "  query_vec = word_matrix[query_id]\n",
        "\n",
        "  vocab_size = len(id_to_word)\n",
        "  similarity = np.zeros(vocab_size)\n",
        "  for i in range(vocab_size):\n",
        "    similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
        "\n",
        "  count = 0\n",
        "  for i in (-1 * similarity).argsort():\n",
        "    if id_to_word[i] == query:\n",
        "      continue\n",
        "    print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
        "\n",
        "    count += 1\n",
        "    if count >= top:\n",
        "      return\n",
        "\n",
        "most_similar('you', word_to_id, id_to_word, C, top=5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[query] you\n",
            " goodbye: 0.7071067758832467\n",
            " i: 0.7071067758832467\n",
            " hello: 0.7071067758832467\n",
            " say: 0.0\n",
            " and: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIxbUlZ7QpDI"
      },
      "source": [
        "### 통계 기반 기법 계산하기\n",
        "\n",
        "동시발생 행렬의 원소는 두 단어가 동시에 발생한 횟수를 나타낸다. 그러나, 이 '발생' 횟수라는 것은 사실 그리 좋은 특징이 아니다. 예를 들어, 고빈도 단어 'the'와 일반 명사 'car'을 비교해 본다고 하자. 이 둘은 동시에 발생한 횟수가 꽤 많을 것인데, 이는 'the'와 'car'가 의미가 유사해서라기 보다는, 단지 'the'가 고빈도 단어이기 때문에 동시발생 횟수도 높게 나온 사례라고 할 수 있다.\n",
        "\n",
        "이러한 문제를 해결하기 위해, 조건부확률을 사용하여 PMI 지수라는 것을 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYJN99X5RYy7",
        "outputId": "57ec40cd-6ac3-4029-9a45-c55e93a9d24a"
      },
      "source": [
        "def ppmi(C, verbose=False, eps=1e-8):\n",
        "  M = np.zeros_like(C, dtype=np.float32)\n",
        "  N = np.sum(C)\n",
        "  S = np.sum(C, axis=0)\n",
        "  total = C.shape[0] * C.shape[1]\n",
        "  cnt = 0\n",
        "\n",
        "  for i in range(C.shape[0]):\n",
        "    for j in range(C.shape[1]):\n",
        "      pmi = np.log2(N * C[i, j] / (S[i]*S[j]) + eps)\n",
        "      M[i, j] = max(0, pmi)\n",
        "\n",
        "      if verbose:\n",
        "        cnt += 1\n",
        "        if cnt % (total // 100) == 0:\n",
        "          print('%.1f%% 완료' % (100*cnt/total))\n",
        "\n",
        "  return M\n",
        "\n",
        "np.set_printoptions(precision=3)\n",
        "W = ppmi(C)\n",
        "\n",
        "print(W)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
            " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
            " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
            " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
            " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
            " [0.    0.807 0.    0.    0.    0.    2.807]\n",
            " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBPmPxLhUVGI"
      },
      "source": [
        "### 차원 감소 (dimensionality reduction)\n",
        "\n",
        "ppmi지수의 가장 큰 문제는 corpus의 크기가 커질 수록 단어의 벡터 길이도 같이\n",
        "길어진다는 것이다. 따라서, SVD를 활용한 차원 감소 기법을 활용하뎌 단어의 벡터 길이를 줄여볼 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "W0v-OuDjUUxv",
        "outputId": "8e8e9c25-795e-4f16-e2bc-1b3d8c476e2f"
      },
      "source": [
        "U, S, V = np.linalg.svd(W) # 차원 감소\n",
        "\n",
        "for word, word_id in word_to_id.items():\n",
        "  plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
        "\n",
        "plt.scatter(U[:,0], U[:,1], alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}