{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpKXtISNidUo",
        "outputId": "2b2219eb-fd8d-4724-c6ef-59c11eea0b69"
      },
      "source": [
        "from collections import OrderedDict\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        " \n",
        "def softmax(a):\n",
        "  if a.ndim == 2:\n",
        "    a = a.T\n",
        "    c = np.max(a, axis = 0)\n",
        "    exp_a = np.exp(a - c) # 오버 플로우를 방지하기 위해 c를 빼준다.\n",
        "    exp_a = exp_a / np.sum(exp_a, axis=0)\n",
        "    return exp_a.T\n",
        " \n",
        "  c = np.max(a)\n",
        "  exp_a = np.exp(a - c)\n",
        "  return exp_a / np.sum(exp_a)\n",
        " \n",
        "def cross_entropy_error(x, t):\n",
        "  return -np.sum(t * np.log(x)) / x.shape[0]\n",
        " \n",
        "# affine transformation\n",
        "class Affine:\n",
        "  def __init__(self, W, b):\n",
        "    self.W = W\n",
        "    self.b = b\n",
        "    self.x = None\n",
        "    self.dW = None\n",
        "    self.db = None\n",
        " \n",
        "  def forward(self, x):\n",
        "    self.x = x\n",
        "    out = np.dot(x, self.W) + self.b\n",
        " \n",
        "    return out\n",
        " \n",
        "  def backward(self, dout):\n",
        "    self.dx = np.dot(dout, self.W.T)\n",
        "    self.dW = np.dot(self.x.T, dout)\n",
        "    self.db = np.sum(dout, axis=0)\n",
        "     \n",
        "    return self.dx\n",
        " \n",
        "# 렐루 층\n",
        "class Relu:\n",
        "  def __init__(self):\n",
        "    self.mask = None\n",
        " \n",
        "  def forward(self, x):\n",
        "    self.mask = (x <= 0)\n",
        "    out = x.copy()\n",
        "    out[self.mask] = 0\n",
        " \n",
        "    return out\n",
        " \n",
        "  def backward(self, dout):\n",
        "    dout[self.mask] = 0\n",
        "    dx = dout\n",
        " \n",
        "    return dout\n",
        " \n",
        "# 소프트맥스 함수와, 손실함수가 합쳐진 층\n",
        "class SoftmaxWithLoss:\n",
        "  def __init__(self):\n",
        "    self.loss = None\n",
        "    self.y = None\n",
        "    self.t = None\n",
        " \n",
        "  def forward(self, x, t):\n",
        "    self.t = t\n",
        "    self.y = softmax(x)\n",
        "    self.loss = cross_entropy_error(self.y, self.t)\n",
        "    return self.loss\n",
        "  \n",
        "  def backward(self, dout=1):\n",
        "    batch_size = self.t.shape[0]\n",
        "    return (self.y - self.t) / batch_size\n",
        " \n",
        "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
        "    \"\"\"다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)\n",
        "    filter_h : 필터의 높이\n",
        "    filter_w : 필터의 너비\n",
        "    stride : 스트라이드\n",
        "    pad : 패딩\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    col : 2차원 배열\n",
        "    \"\"\"\n",
        "    N, C, H, W = input_data.shape\n",
        "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
        "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
        " \n",
        "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
        "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
        " \n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride*out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride*out_w\n",
        "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
        " \n",
        "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
        "    return col\n",
        " \n",
        "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
        "    \"\"\"(im2col과 반대) 2차원 배열을 입력받아 다수의 이미지 묶음으로 변환한다.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    col : 2차원 배열(입력 데이터)\n",
        "    input_shape : 원래 이미지 데이터의 형상（예：(10, 1, 28, 28)）\n",
        "    filter_h : 필터의 높이\n",
        "    filter_w : 필터의 너비\n",
        "    stride : 스트라이드\n",
        "    pad : 패딩\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    img : 변환된 이미지들\n",
        "    \"\"\"\n",
        "    N, C, H, W = input_shape\n",
        "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
        "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
        "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
        " \n",
        "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride*out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride*out_w\n",
        "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
        " \n",
        "    return img[:, :, pad:H + pad, pad:W + pad]\n",
        " \n",
        "# 합성곱 구현\n",
        "class Convolution:\n",
        "    def __init__(self, W, b, stride=1, pad=0):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "        \n",
        "        # 중간 데이터（backward 시 사용）\n",
        "        self.x = None   \n",
        "        self.col = None\n",
        "        self.col_W = None\n",
        "        \n",
        "        # 가중치와 편향 매개변수의 기울기\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        " \n",
        "    def forward(self, x):\n",
        "        FN, C, FH, FW = self.W.shape\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
        "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
        " \n",
        "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
        "        col_W = self.W.reshape(FN, -1).T\n",
        " \n",
        "        out = np.dot(col, col_W) + self.b\n",
        "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
        " \n",
        "        self.x = x\n",
        "        self.col = col\n",
        "        self.col_W = col_W\n",
        " \n",
        "        return out\n",
        " \n",
        "    def backward(self, dout):\n",
        "        FN, C, FH, FW = self.W.shape\n",
        "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
        " \n",
        "        self.db = np.sum(dout, axis=0)\n",
        "        self.dW = np.dot(self.col.T, dout)\n",
        "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
        " \n",
        "        dcol = np.dot(dout, self.col_W.T)\n",
        "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
        " \n",
        "        return dx\n",
        " \n",
        "# 풀링 구현\n",
        "class Pooling:\n",
        "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
        "        self.pool_h = pool_h\n",
        "        self.pool_w = pool_w\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "        \n",
        "        self.x = None\n",
        "        self.arg_max = None\n",
        " \n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
        "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
        " \n",
        "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
        "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
        " \n",
        "        arg_max = np.argmax(col, axis=1)\n",
        "        out = np.max(col, axis=1)\n",
        "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
        " \n",
        "        self.x = x\n",
        "        self.arg_max = arg_max\n",
        " \n",
        "        return out\n",
        " \n",
        "    def backward(self, dout):\n",
        "        dout = dout.transpose(0, 2, 3, 1)\n",
        "        \n",
        "        pool_size = self.pool_h * self.pool_w\n",
        "        dmax = np.zeros((dout.size, pool_size))\n",
        "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
        "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
        "        \n",
        "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
        "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
        "        \n",
        "        return dx\n",
        " \n",
        "class Flatten:\n",
        "  def __init__(self):\n",
        "    self.N = None\n",
        "    self.C = None\n",
        "    self.H = None\n",
        "    self.W = None\n",
        " \n",
        "  def forward(self, x):\n",
        "    self.N, self.C, self.H, self.W = x.shape\n",
        "    out = x.reshape(self.N, -1)\n",
        "    return out\n",
        "  \n",
        "  def backward(self, dout):\n",
        "    dout_reshape = dout.reshape(self.N, self.C, self.H, self.W)\n",
        "    return dout_reshape\n",
        "    \n",
        "class SimpleConvNet:\n",
        "  def __init__(self, input_dim = (1, 28, 28),\n",
        "               conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
        "               hidden_size=100,\n",
        "               output_size=10,\n",
        "               weight_init_std=0.01,\n",
        "               lr=0.01,\n",
        "               batch_size=300,\n",
        "               epochs=100):\n",
        "    filter_num = conv_param['filter_num']\n",
        "    filter_size = conv_param['filter_size']\n",
        "    filter_pad = conv_param['pad']\n",
        "    filter_stride = conv_param['stride']\n",
        " \n",
        "    input_size = input_dim[1]\n",
        "    # 합성곱 계층의 출력 크기를 계산한다.\n",
        "    conv_output_size = (input_size + 2*filter_pad - filter_size) / filter_stride + 1\n",
        "    # 풀링 계층의 출력 크기를 먼저 계산한다.\n",
        "    pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
        " \n",
        "    # 가중치 초기화\n",
        "    self.params = {}\n",
        "    self.params['W1'] = np.random.randn(filter_num, input_dim[0], filter_size, filter_size) * weight_init_std\n",
        "    self.params['b1'] = np.zeros(filter_num)\n",
        "    self.params['W2'] = np.random.randn(pool_output_size, hidden_size) * weight_init_std\n",
        "    self.params['b2'] = np.zeros(hidden_size)\n",
        "    self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "    self.params['b3'] = np.zeros(output_size)\n",
        " \n",
        "    # 신경망 층 구축\n",
        "    self.layers = OrderedDict()\n",
        "    self.layers['Conv1'] = Convolution(self.params['W1'], \n",
        "                                       self.params['b1'], \n",
        "                                       conv_param['stride'], \n",
        "                                       conv_param['pad'])\n",
        "    self.layers['Relu1'] = Relu()\n",
        "    self.layers['pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
        "    self.layers['flatten'] = Flatten()\n",
        "    self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
        "    self.layers['Relu2'] = Relu()\n",
        "    self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
        "    self.last_layer = SoftmaxWithLoss()\n",
        " \n",
        "    # 하이퍼 파라미터\n",
        "    self.lr = lr\n",
        "    self.batch_size = batch_size\n",
        "    self.epochs = epochs\n",
        " \n",
        "  def predict(self, x):\n",
        "    for name, layer in self.layers.items():\n",
        "      x = layer.forward(x)\n",
        "    return x\n",
        " \n",
        "  def loss(self, x, t):\n",
        "    y = self.predict(x)\n",
        "    return self.last_layer.forward(y, t)\n",
        " \n",
        "  def accuracy(self, x, t):\n",
        "    y = self.predict(x)\n",
        "    y = np.argmax(y, axis=1)\n",
        "    return np.mean(y == np.argmax(t, axis=1)).astype('float')\n",
        " \n",
        "  def gradient(self, x, t):\n",
        "    self.loss(x, t)\n",
        " \n",
        "    dout = 1\n",
        "    dout = self.last_layer.backward(dout)\n",
        " \n",
        "    layers = list(self.layers.values())\n",
        "    layers.reverse()\n",
        " \n",
        "    for layer in layers:\n",
        "      dout = layer.backward(dout)\n",
        " \n",
        "    grads = {}\n",
        "    grads['W1'] = self.layers['Conv1'].dW\n",
        "    grads['b1'] = self.layers['Conv1'].db\n",
        "    grads['W2'] = self.layers['Affine1'].dW\n",
        "    grads['b2'] = self.layers['Affine1'].db\n",
        "    grads['W3'] = self.layers['Affine2'].dW\n",
        "    grads['b3'] = self.layers['Affine2'].db\n",
        " \n",
        "    return grads\n",
        " \n",
        "  def generate_batch(self, x, t):\n",
        "    random_mask = np.random.permutation(range(x.shape[0]))\n",
        "    x = x[random_mask]\n",
        "    t = t[random_mask]\n",
        " \n",
        "    batch_iters = int(x.shape[0] / self.batch_size)\n",
        " \n",
        "    for i in range(batch_iters):\n",
        "      start = i * self.batch_size\n",
        "      end = (i+1) * self.batch_size\n",
        "      yield x[start:end], t[start:end]\n",
        "  \n",
        "  # 학습 함수\n",
        "  def fit(self, x, t):\n",
        "    print()\n",
        "    print(\"============= 학습 시작 =============\")\n",
        "    history = {}\n",
        "    history['loss'] = []\n",
        "    history['acc'] = []\n",
        " \n",
        "    for i in range(self.epochs):\n",
        "      train_batch_loss = []\n",
        "      train_batch_acc = []\n",
        "      for x_batch, t_batch in self.generate_batch(x, t):\n",
        "        grad = network.gradient(x_batch, t_batch)\n",
        " \n",
        "        for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "          self.params[key] -= self.lr * grad[key]\n",
        "        \n",
        "        train_batch_loss.append(self.loss(x_batch, t_batch))\n",
        "        train_batch_acc.append(self.accuracy(x_batch, t_batch))\n",
        "      loss_mean = np.mean(train_batch_loss)\n",
        "      acc_mean = np.mean(train_batch_acc)\n",
        " \n",
        "      history['loss'].append(loss_mean)\n",
        "      history['acc'].append(acc_mean)\n",
        "      print(\"epochs: %d; loss: %f; accuracy: %f\" % (i, loss_mean, acc_mean))\n",
        "    return history\n",
        " \n",
        "(x_train, t_train), (x_test, t_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = (x_train / 255.0).astype(np.float32)\n",
        " \n",
        "x_train = x_train[:1000]\n",
        "x_train = x_train.reshape(1000, 1, 28, 28)\n",
        "t_train = t_train[:1000]\n",
        "t_train = to_categorical(t_train)\n",
        " \n",
        "network = SimpleConvNet(batch_size=100, epochs=1000)\n",
        "history = network.fit(x_train, t_train)\n",
        " \n",
        "# 결과값 그리기\n",
        "plt.plot(range(network.epochs), history['loss'], label=\"train loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        " \n",
        "plt.plot(range(network.epochs), history['acc'], label=\"train acc\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        " \n",
        "plt.plot(range(network.epochs), history['acc'], label=\"train acc\")\n",
        " \n",
        "plt.plot(range(network.epochs), history['acc'], label=\"train acc\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "============= 학습 시작 =============\n",
            "epochs: 0; loss: 2.302459; accuracy: 0.123000\n",
            "epochs: 1; loss: 2.302438; accuracy: 0.128000\n",
            "epochs: 2; loss: 2.302416; accuracy: 0.133000\n",
            "epochs: 3; loss: 2.302395; accuracy: 0.140000\n",
            "epochs: 4; loss: 2.302374; accuracy: 0.151000\n",
            "epochs: 5; loss: 2.302352; accuracy: 0.155000\n",
            "epochs: 6; loss: 2.302330; accuracy: 0.158000\n",
            "epochs: 7; loss: 2.302309; accuracy: 0.167000\n",
            "epochs: 8; loss: 2.302288; accuracy: 0.174000\n",
            "epochs: 9; loss: 2.302266; accuracy: 0.188000\n",
            "epochs: 10; loss: 2.302244; accuracy: 0.200000\n",
            "epochs: 11; loss: 2.302223; accuracy: 0.208000\n",
            "epochs: 12; loss: 2.302201; accuracy: 0.216000\n",
            "epochs: 13; loss: 2.302179; accuracy: 0.229000\n",
            "epochs: 14; loss: 2.302157; accuracy: 0.240000\n",
            "epochs: 15; loss: 2.302135; accuracy: 0.250000\n",
            "epochs: 16; loss: 2.302112; accuracy: 0.256000\n",
            "epochs: 17; loss: 2.302089; accuracy: 0.266000\n",
            "epochs: 18; loss: 2.302066; accuracy: 0.276000\n",
            "epochs: 19; loss: 2.302043; accuracy: 0.290000\n",
            "epochs: 20; loss: 2.302019; accuracy: 0.297000\n",
            "epochs: 21; loss: 2.301995; accuracy: 0.307000\n",
            "epochs: 22; loss: 2.301971; accuracy: 0.318000\n",
            "epochs: 23; loss: 2.301946; accuracy: 0.324000\n",
            "epochs: 24; loss: 2.301920; accuracy: 0.335000\n",
            "epochs: 25; loss: 2.301895; accuracy: 0.341000\n",
            "epochs: 26; loss: 2.301868; accuracy: 0.355000\n",
            "epochs: 27; loss: 2.301842; accuracy: 0.361000\n",
            "epochs: 28; loss: 2.301814; accuracy: 0.367000\n",
            "epochs: 29; loss: 2.301787; accuracy: 0.377000\n",
            "epochs: 30; loss: 2.301758; accuracy: 0.385000\n",
            "epochs: 31; loss: 2.301729; accuracy: 0.388000\n",
            "epochs: 32; loss: 2.301700; accuracy: 0.391000\n",
            "epochs: 33; loss: 2.301670; accuracy: 0.404000\n",
            "epochs: 34; loss: 2.301639; accuracy: 0.414000\n",
            "epochs: 35; loss: 2.301607; accuracy: 0.420000\n",
            "epochs: 36; loss: 2.301575; accuracy: 0.427000\n",
            "epochs: 37; loss: 2.301542; accuracy: 0.435000\n",
            "epochs: 38; loss: 2.301508; accuracy: 0.442000\n",
            "epochs: 39; loss: 2.301473; accuracy: 0.450000\n",
            "epochs: 40; loss: 2.301438; accuracy: 0.457000\n",
            "epochs: 41; loss: 2.301402; accuracy: 0.459000\n",
            "epochs: 42; loss: 2.301364; accuracy: 0.464000\n",
            "epochs: 43; loss: 2.301327; accuracy: 0.469000\n",
            "epochs: 44; loss: 2.301288; accuracy: 0.477000\n",
            "epochs: 45; loss: 2.301248; accuracy: 0.481000\n",
            "epochs: 46; loss: 2.301207; accuracy: 0.488000\n",
            "epochs: 47; loss: 2.301166; accuracy: 0.496000\n",
            "epochs: 48; loss: 2.301123; accuracy: 0.500000\n",
            "epochs: 49; loss: 2.301079; accuracy: 0.506000\n",
            "epochs: 50; loss: 2.301035; accuracy: 0.508000\n",
            "epochs: 51; loss: 2.300988; accuracy: 0.510000\n",
            "epochs: 52; loss: 2.300941; accuracy: 0.512000\n",
            "epochs: 53; loss: 2.300893; accuracy: 0.516000\n",
            "epochs: 54; loss: 2.300843; accuracy: 0.521000\n",
            "epochs: 55; loss: 2.300792; accuracy: 0.524000\n",
            "epochs: 56; loss: 2.300739; accuracy: 0.530000\n",
            "epochs: 57; loss: 2.300685; accuracy: 0.532000\n",
            "epochs: 58; loss: 2.300629; accuracy: 0.534000\n",
            "epochs: 59; loss: 2.300572; accuracy: 0.536000\n",
            "epochs: 60; loss: 2.300513; accuracy: 0.538000\n",
            "epochs: 61; loss: 2.300453; accuracy: 0.541000\n",
            "epochs: 62; loss: 2.300390; accuracy: 0.545000\n",
            "epochs: 63; loss: 2.300326; accuracy: 0.550000\n",
            "epochs: 64; loss: 2.300260; accuracy: 0.550000\n",
            "epochs: 65; loss: 2.300193; accuracy: 0.555000\n",
            "epochs: 66; loss: 2.300123; accuracy: 0.555000\n",
            "epochs: 67; loss: 2.300051; accuracy: 0.560000\n",
            "epochs: 68; loss: 2.299977; accuracy: 0.563000\n",
            "epochs: 69; loss: 2.299902; accuracy: 0.563000\n",
            "epochs: 70; loss: 2.299824; accuracy: 0.564000\n",
            "epochs: 71; loss: 2.299743; accuracy: 0.566000\n",
            "epochs: 72; loss: 2.299660; accuracy: 0.565000\n",
            "epochs: 73; loss: 2.299574; accuracy: 0.567000\n",
            "epochs: 74; loss: 2.299486; accuracy: 0.572000\n",
            "epochs: 75; loss: 2.299395; accuracy: 0.574000\n",
            "epochs: 76; loss: 2.299301; accuracy: 0.573000\n",
            "epochs: 77; loss: 2.299204; accuracy: 0.578000\n",
            "epochs: 78; loss: 2.299105; accuracy: 0.578000\n",
            "epochs: 79; loss: 2.299001; accuracy: 0.580000\n",
            "epochs: 80; loss: 2.298896; accuracy: 0.584000\n",
            "epochs: 81; loss: 2.298786; accuracy: 0.587000\n",
            "epochs: 82; loss: 2.298674; accuracy: 0.590000\n",
            "epochs: 83; loss: 2.298559; accuracy: 0.591000\n",
            "epochs: 84; loss: 2.298440; accuracy: 0.596000\n",
            "epochs: 85; loss: 2.298317; accuracy: 0.595000\n",
            "epochs: 86; loss: 2.298191; accuracy: 0.598000\n",
            "epochs: 87; loss: 2.298060; accuracy: 0.599000\n",
            "epochs: 88; loss: 2.297925; accuracy: 0.598000\n",
            "epochs: 89; loss: 2.297787; accuracy: 0.600000\n",
            "epochs: 90; loss: 2.297645; accuracy: 0.599000\n",
            "epochs: 91; loss: 2.297499; accuracy: 0.600000\n",
            "epochs: 92; loss: 2.297348; accuracy: 0.606000\n",
            "epochs: 93; loss: 2.297192; accuracy: 0.606000\n",
            "epochs: 94; loss: 2.297033; accuracy: 0.606000\n",
            "epochs: 95; loss: 2.296868; accuracy: 0.606000\n",
            "epochs: 96; loss: 2.296698; accuracy: 0.606000\n",
            "epochs: 97; loss: 2.296523; accuracy: 0.610000\n",
            "epochs: 98; loss: 2.296344; accuracy: 0.610000\n",
            "epochs: 99; loss: 2.296159; accuracy: 0.613000\n",
            "epochs: 100; loss: 2.295968; accuracy: 0.610000\n",
            "epochs: 101; loss: 2.295771; accuracy: 0.611000\n",
            "epochs: 102; loss: 2.295569; accuracy: 0.610000\n",
            "epochs: 103; loss: 2.295360; accuracy: 0.611000\n",
            "epochs: 104; loss: 2.295145; accuracy: 0.610000\n",
            "epochs: 105; loss: 2.294923; accuracy: 0.610000\n",
            "epochs: 106; loss: 2.294694; accuracy: 0.612000\n",
            "epochs: 107; loss: 2.294457; accuracy: 0.613000\n",
            "epochs: 108; loss: 2.294214; accuracy: 0.612000\n",
            "epochs: 109; loss: 2.293961; accuracy: 0.611000\n",
            "epochs: 110; loss: 2.293702; accuracy: 0.614000\n",
            "epochs: 111; loss: 2.293434; accuracy: 0.616000\n",
            "epochs: 112; loss: 2.293156; accuracy: 0.615000\n",
            "epochs: 113; loss: 2.292871; accuracy: 0.616000\n",
            "epochs: 114; loss: 2.292578; accuracy: 0.617000\n",
            "epochs: 115; loss: 2.292273; accuracy: 0.614000\n",
            "epochs: 116; loss: 2.291958; accuracy: 0.617000\n",
            "epochs: 117; loss: 2.291632; accuracy: 0.616000\n",
            "epochs: 118; loss: 2.291300; accuracy: 0.619000\n",
            "epochs: 119; loss: 2.290952; accuracy: 0.618000\n",
            "epochs: 120; loss: 2.290595; accuracy: 0.618000\n",
            "epochs: 121; loss: 2.290225; accuracy: 0.618000\n",
            "epochs: 122; loss: 2.289843; accuracy: 0.615000\n",
            "epochs: 123; loss: 2.289448; accuracy: 0.618000\n",
            "epochs: 124; loss: 2.289043; accuracy: 0.617000\n",
            "epochs: 125; loss: 2.288621; accuracy: 0.616000\n",
            "epochs: 126; loss: 2.288188; accuracy: 0.615000\n",
            "epochs: 127; loss: 2.287740; accuracy: 0.618000\n",
            "epochs: 128; loss: 2.287276; accuracy: 0.613000\n",
            "epochs: 129; loss: 2.286796; accuracy: 0.619000\n",
            "epochs: 130; loss: 2.286300; accuracy: 0.617000\n",
            "epochs: 131; loss: 2.285792; accuracy: 0.615000\n",
            "epochs: 132; loss: 2.285261; accuracy: 0.617000\n",
            "epochs: 133; loss: 2.284718; accuracy: 0.612000\n",
            "epochs: 134; loss: 2.284151; accuracy: 0.611000\n",
            "epochs: 135; loss: 2.283569; accuracy: 0.611000\n",
            "epochs: 136; loss: 2.282964; accuracy: 0.612000\n",
            "epochs: 137; loss: 2.282343; accuracy: 0.613000\n",
            "epochs: 138; loss: 2.281700; accuracy: 0.611000\n",
            "epochs: 139; loss: 2.281043; accuracy: 0.612000\n",
            "epochs: 140; loss: 2.280360; accuracy: 0.614000\n",
            "epochs: 141; loss: 2.279651; accuracy: 0.612000\n",
            "epochs: 142; loss: 2.278923; accuracy: 0.611000\n",
            "epochs: 143; loss: 2.278171; accuracy: 0.610000\n",
            "epochs: 144; loss: 2.277395; accuracy: 0.612000\n",
            "epochs: 145; loss: 2.276590; accuracy: 0.607000\n",
            "epochs: 146; loss: 2.275761; accuracy: 0.612000\n",
            "epochs: 147; loss: 2.274903; accuracy: 0.611000\n",
            "epochs: 148; loss: 2.274027; accuracy: 0.608000\n",
            "epochs: 149; loss: 2.273113; accuracy: 0.609000\n",
            "epochs: 150; loss: 2.272161; accuracy: 0.612000\n",
            "epochs: 151; loss: 2.271195; accuracy: 0.611000\n",
            "epochs: 152; loss: 2.270187; accuracy: 0.608000\n",
            "epochs: 153; loss: 2.269141; accuracy: 0.609000\n",
            "epochs: 154; loss: 2.268061; accuracy: 0.607000\n",
            "epochs: 155; loss: 2.266957; accuracy: 0.608000\n",
            "epochs: 156; loss: 2.265804; accuracy: 0.607000\n",
            "epochs: 157; loss: 2.264617; accuracy: 0.606000\n",
            "epochs: 158; loss: 2.263388; accuracy: 0.606000\n",
            "epochs: 159; loss: 2.262125; accuracy: 0.606000\n",
            "epochs: 160; loss: 2.260835; accuracy: 0.607000\n",
            "epochs: 161; loss: 2.259494; accuracy: 0.609000\n",
            "epochs: 162; loss: 2.258102; accuracy: 0.608000\n",
            "epochs: 163; loss: 2.256678; accuracy: 0.605000\n",
            "epochs: 164; loss: 2.255211; accuracy: 0.605000\n",
            "epochs: 165; loss: 2.253688; accuracy: 0.609000\n",
            "epochs: 166; loss: 2.252131; accuracy: 0.606000\n",
            "epochs: 167; loss: 2.250519; accuracy: 0.607000\n",
            "epochs: 168; loss: 2.248848; accuracy: 0.607000\n",
            "epochs: 169; loss: 2.247131; accuracy: 0.612000\n",
            "epochs: 170; loss: 2.245362; accuracy: 0.609000\n",
            "epochs: 171; loss: 2.243516; accuracy: 0.609000\n",
            "epochs: 172; loss: 2.241654; accuracy: 0.609000\n",
            "epochs: 173; loss: 2.239699; accuracy: 0.610000\n",
            "epochs: 174; loss: 2.237694; accuracy: 0.609000\n",
            "epochs: 175; loss: 2.235637; accuracy: 0.610000\n",
            "epochs: 176; loss: 2.233520; accuracy: 0.611000\n",
            "epochs: 177; loss: 2.231333; accuracy: 0.612000\n",
            "epochs: 178; loss: 2.229073; accuracy: 0.612000\n",
            "epochs: 179; loss: 2.226752; accuracy: 0.613000\n",
            "epochs: 180; loss: 2.224359; accuracy: 0.614000\n",
            "epochs: 181; loss: 2.221872; accuracy: 0.617000\n",
            "epochs: 182; loss: 2.219346; accuracy: 0.614000\n",
            "epochs: 183; loss: 2.216731; accuracy: 0.616000\n",
            "epochs: 184; loss: 2.214027; accuracy: 0.617000\n",
            "epochs: 185; loss: 2.211267; accuracy: 0.619000\n",
            "epochs: 186; loss: 2.208410; accuracy: 0.618000\n",
            "epochs: 187; loss: 2.205471; accuracy: 0.618000\n",
            "epochs: 188; loss: 2.202428; accuracy: 0.617000\n",
            "epochs: 189; loss: 2.199306; accuracy: 0.617000\n",
            "epochs: 190; loss: 2.196107; accuracy: 0.620000\n",
            "epochs: 191; loss: 2.192814; accuracy: 0.618000\n",
            "epochs: 192; loss: 2.189410; accuracy: 0.619000\n",
            "epochs: 193; loss: 2.185946; accuracy: 0.619000\n",
            "epochs: 194; loss: 2.182338; accuracy: 0.622000\n",
            "epochs: 195; loss: 2.178653; accuracy: 0.621000\n",
            "epochs: 196; loss: 2.174886; accuracy: 0.621000\n",
            "epochs: 197; loss: 2.170998; accuracy: 0.621000\n",
            "epochs: 198; loss: 2.166983; accuracy: 0.622000\n",
            "epochs: 199; loss: 2.162876; accuracy: 0.621000\n",
            "epochs: 200; loss: 2.158660; accuracy: 0.624000\n",
            "epochs: 201; loss: 2.154318; accuracy: 0.626000\n",
            "epochs: 202; loss: 2.149889; accuracy: 0.628000\n",
            "epochs: 203; loss: 2.145317; accuracy: 0.629000\n",
            "epochs: 204; loss: 2.140604; accuracy: 0.631000\n",
            "epochs: 205; loss: 2.135829; accuracy: 0.630000\n",
            "epochs: 206; loss: 2.130915; accuracy: 0.631000\n",
            "epochs: 207; loss: 2.125810; accuracy: 0.631000\n",
            "epochs: 208; loss: 2.120621; accuracy: 0.635000\n",
            "epochs: 209; loss: 2.115310; accuracy: 0.633000\n",
            "epochs: 210; loss: 2.109893; accuracy: 0.635000\n",
            "epochs: 211; loss: 2.104238; accuracy: 0.638000\n",
            "epochs: 212; loss: 2.098561; accuracy: 0.635000\n",
            "epochs: 213; loss: 2.092733; accuracy: 0.642000\n",
            "epochs: 214; loss: 2.086707; accuracy: 0.640000\n",
            "epochs: 215; loss: 2.080580; accuracy: 0.638000\n",
            "epochs: 216; loss: 2.074277; accuracy: 0.642000\n",
            "epochs: 217; loss: 2.067880; accuracy: 0.645000\n",
            "epochs: 218; loss: 2.061305; accuracy: 0.643000\n",
            "epochs: 219; loss: 2.054590; accuracy: 0.647000\n",
            "epochs: 220; loss: 2.047679; accuracy: 0.653000\n",
            "epochs: 221; loss: 2.040716; accuracy: 0.648000\n",
            "epochs: 222; loss: 2.033520; accuracy: 0.646000\n",
            "epochs: 223; loss: 2.026210; accuracy: 0.647000\n",
            "epochs: 224; loss: 2.018686; accuracy: 0.647000\n",
            "epochs: 225; loss: 2.011140; accuracy: 0.651000\n",
            "epochs: 226; loss: 2.003321; accuracy: 0.655000\n",
            "epochs: 227; loss: 1.995422; accuracy: 0.655000\n",
            "epochs: 228; loss: 1.987312; accuracy: 0.654000\n",
            "epochs: 229; loss: 1.979046; accuracy: 0.653000\n",
            "epochs: 230; loss: 1.970637; accuracy: 0.657000\n",
            "epochs: 231; loss: 1.962186; accuracy: 0.658000\n",
            "epochs: 232; loss: 1.953460; accuracy: 0.661000\n",
            "epochs: 233; loss: 1.944520; accuracy: 0.662000\n",
            "epochs: 234; loss: 1.935583; accuracy: 0.668000\n",
            "epochs: 235; loss: 1.926405; accuracy: 0.671000\n",
            "epochs: 236; loss: 1.917138; accuracy: 0.668000\n",
            "epochs: 237; loss: 1.907637; accuracy: 0.671000\n",
            "epochs: 238; loss: 1.898102; accuracy: 0.673000\n",
            "epochs: 239; loss: 1.888220; accuracy: 0.677000\n",
            "epochs: 240; loss: 1.878364; accuracy: 0.680000\n",
            "epochs: 241; loss: 1.868340; accuracy: 0.686000\n",
            "epochs: 242; loss: 1.858223; accuracy: 0.684000\n",
            "epochs: 243; loss: 1.847833; accuracy: 0.685000\n",
            "epochs: 244; loss: 1.837390; accuracy: 0.687000\n",
            "epochs: 245; loss: 1.826858; accuracy: 0.687000\n",
            "epochs: 246; loss: 1.816130; accuracy: 0.689000\n",
            "epochs: 247; loss: 1.805219; accuracy: 0.692000\n",
            "epochs: 248; loss: 1.794293; accuracy: 0.695000\n",
            "epochs: 249; loss: 1.783202; accuracy: 0.694000\n",
            "epochs: 250; loss: 1.772001; accuracy: 0.696000\n",
            "epochs: 251; loss: 1.760727; accuracy: 0.696000\n",
            "epochs: 252; loss: 1.749284; accuracy: 0.697000\n",
            "epochs: 253; loss: 1.737813; accuracy: 0.697000\n",
            "epochs: 254; loss: 1.726327; accuracy: 0.701000\n",
            "epochs: 255; loss: 1.714418; accuracy: 0.703000\n",
            "epochs: 256; loss: 1.702778; accuracy: 0.703000\n",
            "epochs: 257; loss: 1.690877; accuracy: 0.705000\n",
            "epochs: 258; loss: 1.678854; accuracy: 0.707000\n",
            "epochs: 259; loss: 1.666604; accuracy: 0.712000\n",
            "epochs: 260; loss: 1.654621; accuracy: 0.712000\n",
            "epochs: 261; loss: 1.642330; accuracy: 0.717000\n",
            "epochs: 262; loss: 1.630020; accuracy: 0.719000\n",
            "epochs: 263; loss: 1.617753; accuracy: 0.721000\n",
            "epochs: 264; loss: 1.605242; accuracy: 0.727000\n",
            "epochs: 265; loss: 1.592729; accuracy: 0.725000\n",
            "epochs: 266; loss: 1.580461; accuracy: 0.728000\n",
            "epochs: 267; loss: 1.567900; accuracy: 0.731000\n",
            "epochs: 268; loss: 1.555528; accuracy: 0.734000\n",
            "epochs: 269; loss: 1.543012; accuracy: 0.734000\n",
            "epochs: 270; loss: 1.530620; accuracy: 0.737000\n",
            "epochs: 271; loss: 1.518192; accuracy: 0.738000\n",
            "epochs: 272; loss: 1.505818; accuracy: 0.740000\n",
            "epochs: 273; loss: 1.493161; accuracy: 0.745000\n",
            "epochs: 274; loss: 1.480927; accuracy: 0.744000\n",
            "epochs: 275; loss: 1.468542; accuracy: 0.746000\n",
            "epochs: 276; loss: 1.456215; accuracy: 0.749000\n",
            "epochs: 277; loss: 1.443713; accuracy: 0.750000\n",
            "epochs: 278; loss: 1.431525; accuracy: 0.750000\n",
            "epochs: 279; loss: 1.419324; accuracy: 0.751000\n",
            "epochs: 280; loss: 1.407118; accuracy: 0.751000\n",
            "epochs: 281; loss: 1.395111; accuracy: 0.751000\n",
            "epochs: 282; loss: 1.383023; accuracy: 0.753000\n",
            "epochs: 283; loss: 1.371069; accuracy: 0.752000\n",
            "epochs: 284; loss: 1.358952; accuracy: 0.754000\n",
            "epochs: 285; loss: 1.347223; accuracy: 0.758000\n",
            "epochs: 286; loss: 1.335466; accuracy: 0.758000\n",
            "epochs: 287; loss: 1.323661; accuracy: 0.759000\n",
            "epochs: 288; loss: 1.311983; accuracy: 0.762000\n",
            "epochs: 289; loss: 1.300740; accuracy: 0.761000\n",
            "epochs: 290; loss: 1.289239; accuracy: 0.763000\n",
            "epochs: 291; loss: 1.277770; accuracy: 0.765000\n",
            "epochs: 292; loss: 1.266595; accuracy: 0.765000\n",
            "epochs: 293; loss: 1.255548; accuracy: 0.765000\n",
            "epochs: 294; loss: 1.244499; accuracy: 0.765000\n",
            "epochs: 295; loss: 1.233534; accuracy: 0.764000\n",
            "epochs: 296; loss: 1.222714; accuracy: 0.770000\n",
            "epochs: 297; loss: 1.212026; accuracy: 0.771000\n",
            "epochs: 298; loss: 1.201463; accuracy: 0.773000\n",
            "epochs: 299; loss: 1.190935; accuracy: 0.774000\n",
            "epochs: 300; loss: 1.180577; accuracy: 0.776000\n",
            "epochs: 301; loss: 1.170397; accuracy: 0.779000\n",
            "epochs: 302; loss: 1.160278; accuracy: 0.783000\n",
            "epochs: 303; loss: 1.150102; accuracy: 0.779000\n",
            "epochs: 304; loss: 1.140126; accuracy: 0.783000\n",
            "epochs: 305; loss: 1.130299; accuracy: 0.784000\n",
            "epochs: 306; loss: 1.120731; accuracy: 0.790000\n",
            "epochs: 307; loss: 1.111347; accuracy: 0.793000\n",
            "epochs: 308; loss: 1.101894; accuracy: 0.794000\n",
            "epochs: 309; loss: 1.092432; accuracy: 0.795000\n",
            "epochs: 310; loss: 1.083349; accuracy: 0.796000\n",
            "epochs: 311; loss: 1.074347; accuracy: 0.794000\n",
            "epochs: 312; loss: 1.065257; accuracy: 0.797000\n",
            "epochs: 313; loss: 1.056587; accuracy: 0.795000\n",
            "epochs: 314; loss: 1.047643; accuracy: 0.797000\n",
            "epochs: 315; loss: 1.039354; accuracy: 0.797000\n",
            "epochs: 316; loss: 1.030802; accuracy: 0.801000\n",
            "epochs: 317; loss: 1.022708; accuracy: 0.802000\n",
            "epochs: 318; loss: 1.014364; accuracy: 0.806000\n",
            "epochs: 319; loss: 1.006216; accuracy: 0.806000\n",
            "epochs: 320; loss: 0.998221; accuracy: 0.807000\n",
            "epochs: 321; loss: 0.990420; accuracy: 0.809000\n",
            "epochs: 322; loss: 0.982794; accuracy: 0.810000\n",
            "epochs: 323; loss: 0.975296; accuracy: 0.811000\n",
            "epochs: 324; loss: 0.967378; accuracy: 0.814000\n",
            "epochs: 325; loss: 0.960323; accuracy: 0.814000\n",
            "epochs: 326; loss: 0.953008; accuracy: 0.814000\n",
            "epochs: 327; loss: 0.945844; accuracy: 0.816000\n",
            "epochs: 328; loss: 0.938594; accuracy: 0.814000\n",
            "epochs: 329; loss: 0.931982; accuracy: 0.818000\n",
            "epochs: 330; loss: 0.925015; accuracy: 0.816000\n",
            "epochs: 331; loss: 0.918203; accuracy: 0.817000\n",
            "epochs: 332; loss: 0.911413; accuracy: 0.816000\n",
            "epochs: 333; loss: 0.905167; accuracy: 0.816000\n",
            "epochs: 334; loss: 0.898749; accuracy: 0.817000\n",
            "epochs: 335; loss: 0.892540; accuracy: 0.818000\n",
            "epochs: 336; loss: 0.886108; accuracy: 0.817000\n",
            "epochs: 337; loss: 0.880039; accuracy: 0.821000\n",
            "epochs: 338; loss: 0.874034; accuracy: 0.821000\n",
            "epochs: 339; loss: 0.868019; accuracy: 0.818000\n",
            "epochs: 340; loss: 0.862238; accuracy: 0.819000\n",
            "epochs: 341; loss: 0.856358; accuracy: 0.819000\n",
            "epochs: 342; loss: 0.850860; accuracy: 0.818000\n",
            "epochs: 343; loss: 0.845276; accuracy: 0.820000\n",
            "epochs: 344; loss: 0.839753; accuracy: 0.822000\n",
            "epochs: 345; loss: 0.834402; accuracy: 0.819000\n",
            "epochs: 346; loss: 0.829190; accuracy: 0.821000\n",
            "epochs: 347; loss: 0.823869; accuracy: 0.818000\n",
            "epochs: 348; loss: 0.818677; accuracy: 0.822000\n",
            "epochs: 349; loss: 0.813557; accuracy: 0.821000\n",
            "epochs: 350; loss: 0.808527; accuracy: 0.821000\n",
            "epochs: 351; loss: 0.803609; accuracy: 0.822000\n",
            "epochs: 352; loss: 0.798730; accuracy: 0.823000\n",
            "epochs: 353; loss: 0.793999; accuracy: 0.827000\n",
            "epochs: 354; loss: 0.789321; accuracy: 0.824000\n",
            "epochs: 355; loss: 0.784678; accuracy: 0.827000\n",
            "epochs: 356; loss: 0.780006; accuracy: 0.828000\n",
            "epochs: 357; loss: 0.775461; accuracy: 0.829000\n",
            "epochs: 358; loss: 0.771187; accuracy: 0.827000\n",
            "epochs: 359; loss: 0.766879; accuracy: 0.829000\n",
            "epochs: 360; loss: 0.762497; accuracy: 0.831000\n",
            "epochs: 361; loss: 0.758341; accuracy: 0.828000\n",
            "epochs: 362; loss: 0.754153; accuracy: 0.830000\n",
            "epochs: 363; loss: 0.749980; accuracy: 0.834000\n",
            "epochs: 364; loss: 0.746158; accuracy: 0.832000\n",
            "epochs: 365; loss: 0.741979; accuracy: 0.833000\n",
            "epochs: 366; loss: 0.738084; accuracy: 0.833000\n",
            "epochs: 367; loss: 0.734210; accuracy: 0.836000\n",
            "epochs: 368; loss: 0.730513; accuracy: 0.836000\n",
            "epochs: 369; loss: 0.726832; accuracy: 0.836000\n",
            "epochs: 370; loss: 0.722932; accuracy: 0.838000\n",
            "epochs: 371; loss: 0.719355; accuracy: 0.837000\n",
            "epochs: 372; loss: 0.715534; accuracy: 0.838000\n",
            "epochs: 373; loss: 0.711982; accuracy: 0.837000\n",
            "epochs: 374; loss: 0.708456; accuracy: 0.840000\n",
            "epochs: 375; loss: 0.705086; accuracy: 0.838000\n",
            "epochs: 376; loss: 0.701729; accuracy: 0.838000\n",
            "epochs: 377; loss: 0.698324; accuracy: 0.839000\n",
            "epochs: 378; loss: 0.694852; accuracy: 0.839000\n",
            "epochs: 379; loss: 0.691623; accuracy: 0.837000\n",
            "epochs: 380; loss: 0.688579; accuracy: 0.837000\n",
            "epochs: 381; loss: 0.685197; accuracy: 0.841000\n",
            "epochs: 382; loss: 0.682216; accuracy: 0.840000\n",
            "epochs: 383; loss: 0.679105; accuracy: 0.842000\n",
            "epochs: 384; loss: 0.675849; accuracy: 0.843000\n",
            "epochs: 385; loss: 0.673099; accuracy: 0.843000\n",
            "epochs: 386; loss: 0.670122; accuracy: 0.844000\n",
            "epochs: 387; loss: 0.666986; accuracy: 0.847000\n",
            "epochs: 388; loss: 0.664107; accuracy: 0.846000\n",
            "epochs: 389; loss: 0.661258; accuracy: 0.845000\n",
            "epochs: 390; loss: 0.658493; accuracy: 0.847000\n",
            "epochs: 391; loss: 0.655654; accuracy: 0.847000\n",
            "epochs: 392; loss: 0.652943; accuracy: 0.848000\n",
            "epochs: 393; loss: 0.650229; accuracy: 0.849000\n",
            "epochs: 394; loss: 0.647475; accuracy: 0.850000\n",
            "epochs: 395; loss: 0.645036; accuracy: 0.848000\n",
            "epochs: 396; loss: 0.642249; accuracy: 0.849000\n",
            "epochs: 397; loss: 0.639356; accuracy: 0.848000\n",
            "epochs: 398; loss: 0.637159; accuracy: 0.849000\n",
            "epochs: 399; loss: 0.634499; accuracy: 0.850000\n",
            "epochs: 400; loss: 0.632007; accuracy: 0.850000\n",
            "epochs: 401; loss: 0.629629; accuracy: 0.850000\n",
            "epochs: 402; loss: 0.626948; accuracy: 0.850000\n",
            "epochs: 403; loss: 0.624866; accuracy: 0.849000\n",
            "epochs: 404; loss: 0.622279; accuracy: 0.849000\n",
            "epochs: 405; loss: 0.619907; accuracy: 0.851000\n",
            "epochs: 406; loss: 0.617592; accuracy: 0.851000\n",
            "epochs: 407; loss: 0.615384; accuracy: 0.854000\n",
            "epochs: 408; loss: 0.613047; accuracy: 0.853000\n",
            "epochs: 409; loss: 0.610848; accuracy: 0.852000\n",
            "epochs: 410; loss: 0.608488; accuracy: 0.853000\n",
            "epochs: 411; loss: 0.606246; accuracy: 0.854000\n",
            "epochs: 412; loss: 0.604330; accuracy: 0.853000\n",
            "epochs: 413; loss: 0.602127; accuracy: 0.854000\n",
            "epochs: 414; loss: 0.599773; accuracy: 0.853000\n",
            "epochs: 415; loss: 0.597689; accuracy: 0.853000\n",
            "epochs: 416; loss: 0.595827; accuracy: 0.853000\n",
            "epochs: 417; loss: 0.593758; accuracy: 0.853000\n",
            "epochs: 418; loss: 0.591718; accuracy: 0.856000\n",
            "epochs: 419; loss: 0.589681; accuracy: 0.855000\n",
            "epochs: 420; loss: 0.587637; accuracy: 0.854000\n",
            "epochs: 421; loss: 0.585696; accuracy: 0.855000\n",
            "epochs: 422; loss: 0.583776; accuracy: 0.857000\n",
            "epochs: 423; loss: 0.581614; accuracy: 0.855000\n",
            "epochs: 424; loss: 0.579742; accuracy: 0.854000\n",
            "epochs: 425; loss: 0.578038; accuracy: 0.855000\n",
            "epochs: 426; loss: 0.576259; accuracy: 0.855000\n",
            "epochs: 427; loss: 0.574307; accuracy: 0.859000\n",
            "epochs: 428; loss: 0.572371; accuracy: 0.858000\n",
            "epochs: 429; loss: 0.570350; accuracy: 0.860000\n",
            "epochs: 430; loss: 0.568750; accuracy: 0.858000\n",
            "epochs: 431; loss: 0.566943; accuracy: 0.861000\n",
            "epochs: 432; loss: 0.565042; accuracy: 0.859000\n",
            "epochs: 433; loss: 0.563439; accuracy: 0.859000\n",
            "epochs: 434; loss: 0.561750; accuracy: 0.860000\n",
            "epochs: 435; loss: 0.560074; accuracy: 0.859000\n",
            "epochs: 436; loss: 0.558363; accuracy: 0.860000\n",
            "epochs: 437; loss: 0.556802; accuracy: 0.861000\n",
            "epochs: 438; loss: 0.554995; accuracy: 0.862000\n",
            "epochs: 439; loss: 0.553215; accuracy: 0.860000\n",
            "epochs: 440; loss: 0.551850; accuracy: 0.862000\n",
            "epochs: 441; loss: 0.549999; accuracy: 0.864000\n",
            "epochs: 442; loss: 0.548342; accuracy: 0.864000\n",
            "epochs: 443; loss: 0.546902; accuracy: 0.864000\n",
            "epochs: 444; loss: 0.545055; accuracy: 0.865000\n",
            "epochs: 445; loss: 0.543867; accuracy: 0.866000\n",
            "epochs: 446; loss: 0.541951; accuracy: 0.868000\n",
            "epochs: 447; loss: 0.540816; accuracy: 0.866000\n",
            "epochs: 448; loss: 0.539326; accuracy: 0.867000\n",
            "epochs: 449; loss: 0.537702; accuracy: 0.866000\n",
            "epochs: 450; loss: 0.536309; accuracy: 0.869000\n",
            "epochs: 451; loss: 0.534587; accuracy: 0.867000\n",
            "epochs: 452; loss: 0.533420; accuracy: 0.868000\n",
            "epochs: 453; loss: 0.531795; accuracy: 0.866000\n",
            "epochs: 454; loss: 0.530238; accuracy: 0.867000\n",
            "epochs: 455; loss: 0.528950; accuracy: 0.867000\n",
            "epochs: 456; loss: 0.527561; accuracy: 0.869000\n",
            "epochs: 457; loss: 0.526295; accuracy: 0.868000\n",
            "epochs: 458; loss: 0.524880; accuracy: 0.868000\n",
            "epochs: 459; loss: 0.523400; accuracy: 0.869000\n",
            "epochs: 460; loss: 0.521881; accuracy: 0.868000\n",
            "epochs: 461; loss: 0.520689; accuracy: 0.868000\n",
            "epochs: 462; loss: 0.519309; accuracy: 0.869000\n",
            "epochs: 463; loss: 0.518160; accuracy: 0.868000\n",
            "epochs: 464; loss: 0.516643; accuracy: 0.870000\n",
            "epochs: 465; loss: 0.515309; accuracy: 0.868000\n",
            "epochs: 466; loss: 0.514053; accuracy: 0.870000\n",
            "epochs: 467; loss: 0.512687; accuracy: 0.871000\n",
            "epochs: 468; loss: 0.511511; accuracy: 0.872000\n",
            "epochs: 469; loss: 0.510110; accuracy: 0.871000\n",
            "epochs: 470; loss: 0.508933; accuracy: 0.872000\n",
            "epochs: 471; loss: 0.507796; accuracy: 0.870000\n",
            "epochs: 472; loss: 0.506466; accuracy: 0.872000\n",
            "epochs: 473; loss: 0.505283; accuracy: 0.871000\n",
            "epochs: 474; loss: 0.504037; accuracy: 0.870000\n",
            "epochs: 475; loss: 0.503007; accuracy: 0.873000\n",
            "epochs: 476; loss: 0.501638; accuracy: 0.871000\n",
            "epochs: 477; loss: 0.500308; accuracy: 0.872000\n",
            "epochs: 478; loss: 0.499219; accuracy: 0.873000\n",
            "epochs: 479; loss: 0.498014; accuracy: 0.875000\n",
            "epochs: 480; loss: 0.496786; accuracy: 0.874000\n",
            "epochs: 481; loss: 0.495914; accuracy: 0.874000\n",
            "epochs: 482; loss: 0.494142; accuracy: 0.873000\n",
            "epochs: 483; loss: 0.493499; accuracy: 0.874000\n",
            "epochs: 484; loss: 0.492466; accuracy: 0.874000\n",
            "epochs: 485; loss: 0.491244; accuracy: 0.876000\n",
            "epochs: 486; loss: 0.490004; accuracy: 0.874000\n",
            "epochs: 487; loss: 0.489015; accuracy: 0.876000\n",
            "epochs: 488; loss: 0.487838; accuracy: 0.876000\n",
            "epochs: 489; loss: 0.486667; accuracy: 0.875000\n",
            "epochs: 490; loss: 0.485613; accuracy: 0.877000\n",
            "epochs: 491; loss: 0.484743; accuracy: 0.877000\n",
            "epochs: 492; loss: 0.483514; accuracy: 0.878000\n",
            "epochs: 493; loss: 0.482515; accuracy: 0.878000\n",
            "epochs: 494; loss: 0.481190; accuracy: 0.879000\n",
            "epochs: 495; loss: 0.480386; accuracy: 0.880000\n",
            "epochs: 496; loss: 0.479389; accuracy: 0.879000\n",
            "epochs: 497; loss: 0.478327; accuracy: 0.879000\n",
            "epochs: 498; loss: 0.477445; accuracy: 0.879000\n",
            "epochs: 499; loss: 0.476318; accuracy: 0.879000\n",
            "epochs: 500; loss: 0.475200; accuracy: 0.880000\n",
            "epochs: 501; loss: 0.474373; accuracy: 0.880000\n",
            "epochs: 502; loss: 0.473166; accuracy: 0.881000\n",
            "epochs: 503; loss: 0.472269; accuracy: 0.878000\n",
            "epochs: 504; loss: 0.471344; accuracy: 0.882000\n",
            "epochs: 505; loss: 0.470277; accuracy: 0.880000\n",
            "epochs: 506; loss: 0.469510; accuracy: 0.882000\n",
            "epochs: 507; loss: 0.468531; accuracy: 0.882000\n",
            "epochs: 508; loss: 0.467510; accuracy: 0.883000\n",
            "epochs: 509; loss: 0.466406; accuracy: 0.884000\n",
            "epochs: 510; loss: 0.465637; accuracy: 0.884000\n",
            "epochs: 511; loss: 0.464681; accuracy: 0.885000\n",
            "epochs: 512; loss: 0.463673; accuracy: 0.884000\n",
            "epochs: 513; loss: 0.462827; accuracy: 0.885000\n",
            "epochs: 514; loss: 0.462011; accuracy: 0.884000\n",
            "epochs: 515; loss: 0.460890; accuracy: 0.885000\n",
            "epochs: 516; loss: 0.460033; accuracy: 0.885000\n",
            "epochs: 517; loss: 0.459026; accuracy: 0.885000\n",
            "epochs: 518; loss: 0.458360; accuracy: 0.885000\n",
            "epochs: 519; loss: 0.457532; accuracy: 0.885000\n",
            "epochs: 520; loss: 0.456550; accuracy: 0.885000\n",
            "epochs: 521; loss: 0.455600; accuracy: 0.883000\n",
            "epochs: 522; loss: 0.454760; accuracy: 0.884000\n",
            "epochs: 523; loss: 0.454039; accuracy: 0.885000\n",
            "epochs: 524; loss: 0.453042; accuracy: 0.885000\n",
            "epochs: 525; loss: 0.452297; accuracy: 0.885000\n",
            "epochs: 526; loss: 0.451084; accuracy: 0.886000\n",
            "epochs: 527; loss: 0.450603; accuracy: 0.885000\n",
            "epochs: 528; loss: 0.449707; accuracy: 0.885000\n",
            "epochs: 529; loss: 0.448981; accuracy: 0.885000\n",
            "epochs: 530; loss: 0.448081; accuracy: 0.885000\n",
            "epochs: 531; loss: 0.447124; accuracy: 0.885000\n",
            "epochs: 532; loss: 0.446410; accuracy: 0.885000\n",
            "epochs: 533; loss: 0.445678; accuracy: 0.885000\n",
            "epochs: 534; loss: 0.444845; accuracy: 0.885000\n",
            "epochs: 535; loss: 0.444199; accuracy: 0.885000\n",
            "epochs: 536; loss: 0.443368; accuracy: 0.886000\n",
            "epochs: 537; loss: 0.442473; accuracy: 0.886000\n",
            "epochs: 538; loss: 0.441892; accuracy: 0.886000\n",
            "epochs: 539; loss: 0.441003; accuracy: 0.888000\n",
            "epochs: 540; loss: 0.440175; accuracy: 0.888000\n",
            "epochs: 541; loss: 0.439223; accuracy: 0.888000\n",
            "epochs: 542; loss: 0.438873; accuracy: 0.887000\n",
            "epochs: 543; loss: 0.437837; accuracy: 0.889000\n",
            "epochs: 544; loss: 0.436915; accuracy: 0.888000\n",
            "epochs: 545; loss: 0.436454; accuracy: 0.888000\n",
            "epochs: 546; loss: 0.435701; accuracy: 0.888000\n",
            "epochs: 547; loss: 0.434856; accuracy: 0.887000\n",
            "epochs: 548; loss: 0.434336; accuracy: 0.889000\n",
            "epochs: 549; loss: 0.433342; accuracy: 0.889000\n",
            "epochs: 550; loss: 0.432450; accuracy: 0.889000\n",
            "epochs: 551; loss: 0.432000; accuracy: 0.889000\n",
            "epochs: 552; loss: 0.431196; accuracy: 0.891000\n",
            "epochs: 553; loss: 0.430636; accuracy: 0.887000\n",
            "epochs: 554; loss: 0.429775; accuracy: 0.888000\n",
            "epochs: 555; loss: 0.428842; accuracy: 0.888000\n",
            "epochs: 556; loss: 0.428372; accuracy: 0.888000\n",
            "epochs: 557; loss: 0.427705; accuracy: 0.888000\n",
            "epochs: 558; loss: 0.427149; accuracy: 0.890000\n",
            "epochs: 559; loss: 0.426353; accuracy: 0.889000\n",
            "epochs: 560; loss: 0.425533; accuracy: 0.889000\n",
            "epochs: 561; loss: 0.424676; accuracy: 0.890000\n",
            "epochs: 562; loss: 0.424260; accuracy: 0.890000\n",
            "epochs: 563; loss: 0.423479; accuracy: 0.891000\n",
            "epochs: 564; loss: 0.422931; accuracy: 0.890000\n",
            "epochs: 565; loss: 0.422339; accuracy: 0.890000\n",
            "epochs: 566; loss: 0.421503; accuracy: 0.891000\n",
            "epochs: 567; loss: 0.420727; accuracy: 0.889000\n",
            "epochs: 568; loss: 0.420350; accuracy: 0.891000\n",
            "epochs: 569; loss: 0.419636; accuracy: 0.892000\n",
            "epochs: 570; loss: 0.418986; accuracy: 0.891000\n",
            "epochs: 571; loss: 0.418371; accuracy: 0.892000\n",
            "epochs: 572; loss: 0.417616; accuracy: 0.892000\n",
            "epochs: 573; loss: 0.416874; accuracy: 0.891000\n",
            "epochs: 574; loss: 0.416448; accuracy: 0.892000\n",
            "epochs: 575; loss: 0.415721; accuracy: 0.893000\n",
            "epochs: 576; loss: 0.415099; accuracy: 0.891000\n",
            "epochs: 577; loss: 0.414407; accuracy: 0.891000\n",
            "epochs: 578; loss: 0.413869; accuracy: 0.891000\n",
            "epochs: 579; loss: 0.413381; accuracy: 0.892000\n",
            "epochs: 580; loss: 0.412685; accuracy: 0.893000\n",
            "epochs: 581; loss: 0.411646; accuracy: 0.893000\n",
            "epochs: 582; loss: 0.411422; accuracy: 0.892000\n",
            "epochs: 583; loss: 0.410413; accuracy: 0.891000\n",
            "epochs: 584; loss: 0.409995; accuracy: 0.893000\n",
            "epochs: 585; loss: 0.409545; accuracy: 0.894000\n",
            "epochs: 586; loss: 0.409038; accuracy: 0.892000\n",
            "epochs: 587; loss: 0.408240; accuracy: 0.892000\n",
            "epochs: 588; loss: 0.407623; accuracy: 0.893000\n",
            "epochs: 589; loss: 0.407369; accuracy: 0.894000\n",
            "epochs: 590; loss: 0.406554; accuracy: 0.894000\n",
            "epochs: 591; loss: 0.405992; accuracy: 0.893000\n",
            "epochs: 592; loss: 0.405300; accuracy: 0.894000\n",
            "epochs: 593; loss: 0.404839; accuracy: 0.892000\n",
            "epochs: 594; loss: 0.404266; accuracy: 0.893000\n",
            "epochs: 595; loss: 0.403492; accuracy: 0.895000\n",
            "epochs: 596; loss: 0.403180; accuracy: 0.894000\n",
            "epochs: 597; loss: 0.402375; accuracy: 0.894000\n",
            "epochs: 598; loss: 0.401855; accuracy: 0.895000\n",
            "epochs: 599; loss: 0.401470; accuracy: 0.892000\n",
            "epochs: 600; loss: 0.400869; accuracy: 0.894000\n",
            "epochs: 601; loss: 0.400264; accuracy: 0.894000\n",
            "epochs: 602; loss: 0.399651; accuracy: 0.894000\n",
            "epochs: 603; loss: 0.399377; accuracy: 0.893000\n",
            "epochs: 604; loss: 0.398475; accuracy: 0.893000\n",
            "epochs: 605; loss: 0.397991; accuracy: 0.894000\n",
            "epochs: 606; loss: 0.397455; accuracy: 0.895000\n",
            "epochs: 607; loss: 0.396819; accuracy: 0.895000\n",
            "epochs: 608; loss: 0.396145; accuracy: 0.895000\n",
            "epochs: 609; loss: 0.395876; accuracy: 0.895000\n",
            "epochs: 610; loss: 0.395358; accuracy: 0.895000\n",
            "epochs: 611; loss: 0.394856; accuracy: 0.895000\n",
            "epochs: 612; loss: 0.394266; accuracy: 0.894000\n",
            "epochs: 613; loss: 0.393825; accuracy: 0.895000\n",
            "epochs: 614; loss: 0.393124; accuracy: 0.895000\n",
            "epochs: 615; loss: 0.392551; accuracy: 0.895000\n",
            "epochs: 616; loss: 0.392094; accuracy: 0.894000\n",
            "epochs: 617; loss: 0.391528; accuracy: 0.895000\n",
            "epochs: 618; loss: 0.390934; accuracy: 0.895000\n",
            "epochs: 619; loss: 0.390562; accuracy: 0.895000\n",
            "epochs: 620; loss: 0.389989; accuracy: 0.895000\n",
            "epochs: 621; loss: 0.389568; accuracy: 0.894000\n",
            "epochs: 622; loss: 0.388936; accuracy: 0.895000\n",
            "epochs: 623; loss: 0.388516; accuracy: 0.894000\n",
            "epochs: 624; loss: 0.388069; accuracy: 0.894000\n",
            "epochs: 625; loss: 0.387333; accuracy: 0.894000\n",
            "epochs: 626; loss: 0.386896; accuracy: 0.895000\n",
            "epochs: 627; loss: 0.386522; accuracy: 0.895000\n",
            "epochs: 628; loss: 0.385978; accuracy: 0.894000\n",
            "epochs: 629; loss: 0.385355; accuracy: 0.896000\n",
            "epochs: 630; loss: 0.385036; accuracy: 0.895000\n",
            "epochs: 631; loss: 0.384544; accuracy: 0.895000\n",
            "epochs: 632; loss: 0.383911; accuracy: 0.895000\n",
            "epochs: 633; loss: 0.383275; accuracy: 0.896000\n",
            "epochs: 634; loss: 0.383077; accuracy: 0.895000\n",
            "epochs: 635; loss: 0.382390; accuracy: 0.898000\n",
            "epochs: 636; loss: 0.382022; accuracy: 0.895000\n",
            "epochs: 637; loss: 0.381563; accuracy: 0.895000\n",
            "epochs: 638; loss: 0.381038; accuracy: 0.895000\n",
            "epochs: 639; loss: 0.380610; accuracy: 0.895000\n",
            "epochs: 640; loss: 0.380169; accuracy: 0.895000\n",
            "epochs: 641; loss: 0.379646; accuracy: 0.895000\n",
            "epochs: 642; loss: 0.379326; accuracy: 0.895000\n",
            "epochs: 643; loss: 0.378559; accuracy: 0.897000\n",
            "epochs: 644; loss: 0.378400; accuracy: 0.896000\n",
            "epochs: 645; loss: 0.377943; accuracy: 0.898000\n",
            "epochs: 646; loss: 0.377299; accuracy: 0.896000\n",
            "epochs: 647; loss: 0.376901; accuracy: 0.897000\n",
            "epochs: 648; loss: 0.376304; accuracy: 0.898000\n",
            "epochs: 649; loss: 0.375852; accuracy: 0.897000\n",
            "epochs: 650; loss: 0.375347; accuracy: 0.896000\n",
            "epochs: 651; loss: 0.374968; accuracy: 0.896000\n",
            "epochs: 652; loss: 0.374550; accuracy: 0.898000\n",
            "epochs: 653; loss: 0.374061; accuracy: 0.898000\n",
            "epochs: 654; loss: 0.373580; accuracy: 0.899000\n",
            "epochs: 655; loss: 0.373112; accuracy: 0.897000\n",
            "epochs: 656; loss: 0.372822; accuracy: 0.898000\n",
            "epochs: 657; loss: 0.372333; accuracy: 0.899000\n",
            "epochs: 658; loss: 0.371900; accuracy: 0.899000\n",
            "epochs: 659; loss: 0.371417; accuracy: 0.899000\n",
            "epochs: 660; loss: 0.371041; accuracy: 0.899000\n",
            "epochs: 661; loss: 0.370526; accuracy: 0.899000\n",
            "epochs: 662; loss: 0.369839; accuracy: 0.898000\n",
            "epochs: 663; loss: 0.369519; accuracy: 0.899000\n",
            "epochs: 664; loss: 0.369168; accuracy: 0.899000\n",
            "epochs: 665; loss: 0.368627; accuracy: 0.900000\n",
            "epochs: 666; loss: 0.368207; accuracy: 0.899000\n",
            "epochs: 667; loss: 0.367851; accuracy: 0.900000\n",
            "epochs: 668; loss: 0.367408; accuracy: 0.901000\n",
            "epochs: 669; loss: 0.366971; accuracy: 0.899000\n",
            "epochs: 670; loss: 0.366626; accuracy: 0.901000\n",
            "epochs: 671; loss: 0.366279; accuracy: 0.900000\n",
            "epochs: 672; loss: 0.365796; accuracy: 0.901000\n",
            "epochs: 673; loss: 0.365310; accuracy: 0.901000\n",
            "epochs: 674; loss: 0.364885; accuracy: 0.900000\n",
            "epochs: 675; loss: 0.364507; accuracy: 0.901000\n",
            "epochs: 676; loss: 0.363956; accuracy: 0.901000\n",
            "epochs: 677; loss: 0.363896; accuracy: 0.900000\n",
            "epochs: 678; loss: 0.363423; accuracy: 0.901000\n",
            "epochs: 679; loss: 0.363016; accuracy: 0.900000\n",
            "epochs: 680; loss: 0.362468; accuracy: 0.900000\n",
            "epochs: 681; loss: 0.361959; accuracy: 0.901000\n",
            "epochs: 682; loss: 0.361594; accuracy: 0.901000\n",
            "epochs: 683; loss: 0.361286; accuracy: 0.901000\n",
            "epochs: 684; loss: 0.360823; accuracy: 0.901000\n",
            "epochs: 685; loss: 0.360334; accuracy: 0.902000\n",
            "epochs: 686; loss: 0.359936; accuracy: 0.902000\n",
            "epochs: 687; loss: 0.359794; accuracy: 0.901000\n",
            "epochs: 688; loss: 0.359106; accuracy: 0.902000\n",
            "epochs: 689; loss: 0.358870; accuracy: 0.902000\n",
            "epochs: 690; loss: 0.358172; accuracy: 0.901000\n",
            "epochs: 691; loss: 0.358135; accuracy: 0.902000\n",
            "epochs: 692; loss: 0.357708; accuracy: 0.901000\n",
            "epochs: 693; loss: 0.357222; accuracy: 0.902000\n",
            "epochs: 694; loss: 0.356650; accuracy: 0.903000\n",
            "epochs: 695; loss: 0.356526; accuracy: 0.901000\n",
            "epochs: 696; loss: 0.356086; accuracy: 0.902000\n",
            "epochs: 697; loss: 0.355663; accuracy: 0.903000\n",
            "epochs: 698; loss: 0.355362; accuracy: 0.901000\n",
            "epochs: 699; loss: 0.354885; accuracy: 0.904000\n",
            "epochs: 700; loss: 0.354578; accuracy: 0.904000\n",
            "epochs: 701; loss: 0.353976; accuracy: 0.903000\n",
            "epochs: 702; loss: 0.353767; accuracy: 0.903000\n",
            "epochs: 703; loss: 0.353204; accuracy: 0.903000\n",
            "epochs: 704; loss: 0.353164; accuracy: 0.904000\n",
            "epochs: 705; loss: 0.352555; accuracy: 0.904000\n",
            "epochs: 706; loss: 0.352277; accuracy: 0.904000\n",
            "epochs: 707; loss: 0.351805; accuracy: 0.906000\n",
            "epochs: 708; loss: 0.351467; accuracy: 0.903000\n",
            "epochs: 709; loss: 0.351229; accuracy: 0.905000\n",
            "epochs: 710; loss: 0.350631; accuracy: 0.903000\n",
            "epochs: 711; loss: 0.350361; accuracy: 0.904000\n",
            "epochs: 712; loss: 0.350116; accuracy: 0.904000\n",
            "epochs: 713; loss: 0.349546; accuracy: 0.904000\n",
            "epochs: 714; loss: 0.349374; accuracy: 0.903000\n",
            "epochs: 715; loss: 0.348901; accuracy: 0.903000\n",
            "epochs: 716; loss: 0.348554; accuracy: 0.903000\n",
            "epochs: 717; loss: 0.348025; accuracy: 0.906000\n",
            "epochs: 718; loss: 0.347879; accuracy: 0.904000\n",
            "epochs: 719; loss: 0.347520; accuracy: 0.902000\n",
            "epochs: 720; loss: 0.347140; accuracy: 0.903000\n",
            "epochs: 721; loss: 0.346738; accuracy: 0.904000\n",
            "epochs: 722; loss: 0.346295; accuracy: 0.903000\n",
            "epochs: 723; loss: 0.346037; accuracy: 0.903000\n",
            "epochs: 724; loss: 0.345616; accuracy: 0.903000\n",
            "epochs: 725; loss: 0.345190; accuracy: 0.904000\n",
            "epochs: 726; loss: 0.344899; accuracy: 0.903000\n",
            "epochs: 727; loss: 0.344784; accuracy: 0.903000\n",
            "epochs: 728; loss: 0.344289; accuracy: 0.903000\n",
            "epochs: 729; loss: 0.343915; accuracy: 0.903000\n",
            "epochs: 730; loss: 0.343401; accuracy: 0.904000\n",
            "epochs: 731; loss: 0.343242; accuracy: 0.903000\n",
            "epochs: 732; loss: 0.342814; accuracy: 0.904000\n",
            "epochs: 733; loss: 0.342432; accuracy: 0.902000\n",
            "epochs: 734; loss: 0.342275; accuracy: 0.903000\n",
            "epochs: 735; loss: 0.341759; accuracy: 0.905000\n",
            "epochs: 736; loss: 0.341402; accuracy: 0.904000\n",
            "epochs: 737; loss: 0.341060; accuracy: 0.903000\n",
            "epochs: 738; loss: 0.340922; accuracy: 0.904000\n",
            "epochs: 739; loss: 0.340492; accuracy: 0.904000\n",
            "epochs: 740; loss: 0.340231; accuracy: 0.904000\n",
            "epochs: 741; loss: 0.339781; accuracy: 0.904000\n",
            "epochs: 742; loss: 0.339401; accuracy: 0.905000\n",
            "epochs: 743; loss: 0.339140; accuracy: 0.903000\n",
            "epochs: 744; loss: 0.338873; accuracy: 0.906000\n",
            "epochs: 745; loss: 0.338435; accuracy: 0.904000\n",
            "epochs: 746; loss: 0.338132; accuracy: 0.905000\n",
            "epochs: 747; loss: 0.337648; accuracy: 0.904000\n",
            "epochs: 748; loss: 0.337615; accuracy: 0.904000\n",
            "epochs: 749; loss: 0.337119; accuracy: 0.904000\n",
            "epochs: 750; loss: 0.336818; accuracy: 0.904000\n",
            "epochs: 751; loss: 0.336372; accuracy: 0.903000\n",
            "epochs: 752; loss: 0.336218; accuracy: 0.905000\n",
            "epochs: 753; loss: 0.335619; accuracy: 0.905000\n",
            "epochs: 754; loss: 0.335352; accuracy: 0.904000\n",
            "epochs: 755; loss: 0.335072; accuracy: 0.904000\n",
            "epochs: 756; loss: 0.334970; accuracy: 0.905000\n",
            "epochs: 757; loss: 0.334642; accuracy: 0.904000\n",
            "epochs: 758; loss: 0.334144; accuracy: 0.904000\n",
            "epochs: 759; loss: 0.333915; accuracy: 0.905000\n",
            "epochs: 760; loss: 0.333645; accuracy: 0.904000\n",
            "epochs: 761; loss: 0.333145; accuracy: 0.904000\n",
            "epochs: 762; loss: 0.332843; accuracy: 0.904000\n",
            "epochs: 763; loss: 0.332693; accuracy: 0.904000\n",
            "epochs: 764; loss: 0.332471; accuracy: 0.905000\n",
            "epochs: 765; loss: 0.331788; accuracy: 0.904000\n",
            "epochs: 766; loss: 0.331817; accuracy: 0.906000\n",
            "epochs: 767; loss: 0.331501; accuracy: 0.904000\n",
            "epochs: 768; loss: 0.330854; accuracy: 0.905000\n",
            "epochs: 769; loss: 0.330544; accuracy: 0.907000\n",
            "epochs: 770; loss: 0.330432; accuracy: 0.904000\n",
            "epochs: 771; loss: 0.330064; accuracy: 0.906000\n",
            "epochs: 772; loss: 0.329636; accuracy: 0.905000\n",
            "epochs: 773; loss: 0.329500; accuracy: 0.905000\n",
            "epochs: 774; loss: 0.329237; accuracy: 0.904000\n",
            "epochs: 775; loss: 0.328884; accuracy: 0.906000\n",
            "epochs: 776; loss: 0.328467; accuracy: 0.905000\n",
            "epochs: 777; loss: 0.328244; accuracy: 0.906000\n",
            "epochs: 778; loss: 0.327829; accuracy: 0.905000\n",
            "epochs: 779; loss: 0.327517; accuracy: 0.906000\n",
            "epochs: 780; loss: 0.327267; accuracy: 0.907000\n",
            "epochs: 781; loss: 0.326943; accuracy: 0.905000\n",
            "epochs: 782; loss: 0.326718; accuracy: 0.907000\n",
            "epochs: 783; loss: 0.326388; accuracy: 0.907000\n",
            "epochs: 784; loss: 0.326142; accuracy: 0.906000\n",
            "epochs: 785; loss: 0.325762; accuracy: 0.906000\n",
            "epochs: 786; loss: 0.325577; accuracy: 0.905000\n",
            "epochs: 787; loss: 0.325144; accuracy: 0.908000\n",
            "epochs: 788; loss: 0.324774; accuracy: 0.908000\n",
            "epochs: 789; loss: 0.324628; accuracy: 0.907000\n",
            "epochs: 790; loss: 0.324212; accuracy: 0.905000\n",
            "epochs: 791; loss: 0.323991; accuracy: 0.907000\n",
            "epochs: 792; loss: 0.323672; accuracy: 0.907000\n",
            "epochs: 793; loss: 0.323358; accuracy: 0.906000\n",
            "epochs: 794; loss: 0.323105; accuracy: 0.907000\n",
            "epochs: 795; loss: 0.322864; accuracy: 0.909000\n",
            "epochs: 796; loss: 0.322458; accuracy: 0.910000\n",
            "epochs: 797; loss: 0.322271; accuracy: 0.908000\n",
            "epochs: 798; loss: 0.321777; accuracy: 0.911000\n",
            "epochs: 799; loss: 0.321622; accuracy: 0.908000\n",
            "epochs: 800; loss: 0.321507; accuracy: 0.909000\n",
            "epochs: 801; loss: 0.321150; accuracy: 0.910000\n",
            "epochs: 802; loss: 0.320765; accuracy: 0.909000\n",
            "epochs: 803; loss: 0.320483; accuracy: 0.912000\n",
            "epochs: 804; loss: 0.320208; accuracy: 0.909000\n",
            "epochs: 805; loss: 0.319970; accuracy: 0.911000\n",
            "epochs: 806; loss: 0.319744; accuracy: 0.909000\n",
            "epochs: 807; loss: 0.319332; accuracy: 0.909000\n",
            "epochs: 808; loss: 0.319131; accuracy: 0.909000\n",
            "epochs: 809; loss: 0.319008; accuracy: 0.910000\n",
            "epochs: 810; loss: 0.318369; accuracy: 0.910000\n",
            "epochs: 811; loss: 0.318387; accuracy: 0.910000\n",
            "epochs: 812; loss: 0.317886; accuracy: 0.911000\n",
            "epochs: 813; loss: 0.317729; accuracy: 0.911000\n",
            "epochs: 814; loss: 0.317439; accuracy: 0.911000\n",
            "epochs: 815; loss: 0.316938; accuracy: 0.913000\n",
            "epochs: 816; loss: 0.316706; accuracy: 0.911000\n",
            "epochs: 817; loss: 0.316685; accuracy: 0.912000\n",
            "epochs: 818; loss: 0.316245; accuracy: 0.912000\n",
            "epochs: 819; loss: 0.315853; accuracy: 0.909000\n",
            "epochs: 820; loss: 0.315595; accuracy: 0.912000\n",
            "epochs: 821; loss: 0.315381; accuracy: 0.912000\n",
            "epochs: 822; loss: 0.315102; accuracy: 0.911000\n",
            "epochs: 823; loss: 0.314933; accuracy: 0.912000\n",
            "epochs: 824; loss: 0.314536; accuracy: 0.913000\n",
            "epochs: 825; loss: 0.314078; accuracy: 0.910000\n",
            "epochs: 826; loss: 0.314039; accuracy: 0.911000\n",
            "epochs: 827; loss: 0.313871; accuracy: 0.912000\n",
            "epochs: 828; loss: 0.313671; accuracy: 0.912000\n",
            "epochs: 829; loss: 0.313402; accuracy: 0.913000\n",
            "epochs: 830; loss: 0.313095; accuracy: 0.914000\n",
            "epochs: 831; loss: 0.312662; accuracy: 0.913000\n",
            "epochs: 832; loss: 0.312406; accuracy: 0.913000\n",
            "epochs: 833; loss: 0.312213; accuracy: 0.914000\n",
            "epochs: 834; loss: 0.311934; accuracy: 0.912000\n",
            "epochs: 835; loss: 0.311734; accuracy: 0.913000\n",
            "epochs: 836; loss: 0.311409; accuracy: 0.914000\n",
            "epochs: 837; loss: 0.311190; accuracy: 0.912000\n",
            "epochs: 838; loss: 0.310867; accuracy: 0.913000\n",
            "epochs: 839; loss: 0.310587; accuracy: 0.914000\n",
            "epochs: 840; loss: 0.310270; accuracy: 0.913000\n",
            "epochs: 841; loss: 0.310115; accuracy: 0.914000\n",
            "epochs: 842; loss: 0.309859; accuracy: 0.912000\n",
            "epochs: 843; loss: 0.309566; accuracy: 0.915000\n",
            "epochs: 844; loss: 0.309318; accuracy: 0.914000\n",
            "epochs: 845; loss: 0.309029; accuracy: 0.914000\n",
            "epochs: 846; loss: 0.308806; accuracy: 0.914000\n",
            "epochs: 847; loss: 0.308566; accuracy: 0.914000\n",
            "epochs: 848; loss: 0.308235; accuracy: 0.914000\n",
            "epochs: 849; loss: 0.308013; accuracy: 0.914000\n",
            "epochs: 850; loss: 0.307868; accuracy: 0.914000\n",
            "epochs: 851; loss: 0.307509; accuracy: 0.914000\n",
            "epochs: 852; loss: 0.307364; accuracy: 0.913000\n",
            "epochs: 853; loss: 0.306803; accuracy: 0.915000\n",
            "epochs: 854; loss: 0.306786; accuracy: 0.914000\n",
            "epochs: 855; loss: 0.306488; accuracy: 0.913000\n",
            "epochs: 856; loss: 0.306155; accuracy: 0.913000\n",
            "epochs: 857; loss: 0.306155; accuracy: 0.914000\n",
            "epochs: 858; loss: 0.305793; accuracy: 0.915000\n",
            "epochs: 859; loss: 0.305637; accuracy: 0.915000\n",
            "epochs: 860; loss: 0.305265; accuracy: 0.915000\n",
            "epochs: 861; loss: 0.305058; accuracy: 0.914000\n",
            "epochs: 862; loss: 0.304751; accuracy: 0.915000\n",
            "epochs: 863; loss: 0.304514; accuracy: 0.915000\n",
            "epochs: 864; loss: 0.304277; accuracy: 0.915000\n",
            "epochs: 865; loss: 0.304155; accuracy: 0.915000\n",
            "epochs: 866; loss: 0.303906; accuracy: 0.915000\n",
            "epochs: 867; loss: 0.303629; accuracy: 0.915000\n",
            "epochs: 868; loss: 0.303134; accuracy: 0.915000\n",
            "epochs: 869; loss: 0.302985; accuracy: 0.915000\n",
            "epochs: 870; loss: 0.302885; accuracy: 0.916000\n",
            "epochs: 871; loss: 0.302475; accuracy: 0.915000\n",
            "epochs: 872; loss: 0.302333; accuracy: 0.914000\n",
            "epochs: 873; loss: 0.302065; accuracy: 0.914000\n",
            "epochs: 874; loss: 0.301858; accuracy: 0.915000\n",
            "epochs: 875; loss: 0.301676; accuracy: 0.915000\n",
            "epochs: 876; loss: 0.301269; accuracy: 0.917000\n",
            "epochs: 877; loss: 0.301252; accuracy: 0.915000\n",
            "epochs: 878; loss: 0.300825; accuracy: 0.916000\n",
            "epochs: 879; loss: 0.300569; accuracy: 0.916000\n",
            "epochs: 880; loss: 0.300335; accuracy: 0.915000\n",
            "epochs: 881; loss: 0.300241; accuracy: 0.917000\n",
            "epochs: 882; loss: 0.299851; accuracy: 0.917000\n",
            "epochs: 883; loss: 0.299749; accuracy: 0.916000\n",
            "epochs: 884; loss: 0.299554; accuracy: 0.916000\n",
            "epochs: 885; loss: 0.299205; accuracy: 0.919000\n",
            "epochs: 886; loss: 0.298780; accuracy: 0.918000\n",
            "epochs: 887; loss: 0.298816; accuracy: 0.916000\n",
            "epochs: 888; loss: 0.298392; accuracy: 0.918000\n",
            "epochs: 889; loss: 0.298362; accuracy: 0.915000\n",
            "epochs: 890; loss: 0.298104; accuracy: 0.916000\n",
            "epochs: 891; loss: 0.297841; accuracy: 0.916000\n",
            "epochs: 892; loss: 0.297446; accuracy: 0.918000\n",
            "epochs: 893; loss: 0.297271; accuracy: 0.918000\n",
            "epochs: 894; loss: 0.297220; accuracy: 0.917000\n",
            "epochs: 895; loss: 0.296922; accuracy: 0.918000\n",
            "epochs: 896; loss: 0.296715; accuracy: 0.916000\n",
            "epochs: 897; loss: 0.296495; accuracy: 0.918000\n",
            "epochs: 898; loss: 0.295980; accuracy: 0.917000\n",
            "epochs: 899; loss: 0.295951; accuracy: 0.919000\n",
            "epochs: 900; loss: 0.295594; accuracy: 0.920000\n",
            "epochs: 901; loss: 0.295549; accuracy: 0.919000\n",
            "epochs: 902; loss: 0.295212; accuracy: 0.921000\n",
            "epochs: 903; loss: 0.294824; accuracy: 0.920000\n",
            "epochs: 904; loss: 0.294823; accuracy: 0.920000\n",
            "epochs: 905; loss: 0.294542; accuracy: 0.921000\n",
            "epochs: 906; loss: 0.294250; accuracy: 0.920000\n",
            "epochs: 907; loss: 0.294102; accuracy: 0.924000\n",
            "epochs: 908; loss: 0.293757; accuracy: 0.922000\n",
            "epochs: 909; loss: 0.293599; accuracy: 0.921000\n",
            "epochs: 910; loss: 0.293333; accuracy: 0.921000\n",
            "epochs: 911; loss: 0.293231; accuracy: 0.919000\n",
            "epochs: 912; loss: 0.293052; accuracy: 0.921000\n",
            "epochs: 913; loss: 0.292766; accuracy: 0.922000\n",
            "epochs: 914; loss: 0.292483; accuracy: 0.921000\n",
            "epochs: 915; loss: 0.292370; accuracy: 0.924000\n",
            "epochs: 916; loss: 0.292196; accuracy: 0.922000\n",
            "epochs: 917; loss: 0.291871; accuracy: 0.923000\n",
            "epochs: 918; loss: 0.291711; accuracy: 0.922000\n",
            "epochs: 919; loss: 0.291526; accuracy: 0.923000\n",
            "epochs: 920; loss: 0.291333; accuracy: 0.921000\n",
            "epochs: 921; loss: 0.290981; accuracy: 0.923000\n",
            "epochs: 922; loss: 0.290790; accuracy: 0.921000\n",
            "epochs: 923; loss: 0.290700; accuracy: 0.923000\n",
            "epochs: 924; loss: 0.290304; accuracy: 0.923000\n",
            "epochs: 925; loss: 0.290281; accuracy: 0.922000\n",
            "epochs: 926; loss: 0.289920; accuracy: 0.923000\n",
            "epochs: 927; loss: 0.289591; accuracy: 0.922000\n",
            "epochs: 928; loss: 0.289565; accuracy: 0.923000\n",
            "epochs: 929; loss: 0.289093; accuracy: 0.922000\n",
            "epochs: 930; loss: 0.289032; accuracy: 0.923000\n",
            "epochs: 931; loss: 0.288830; accuracy: 0.923000\n",
            "epochs: 932; loss: 0.288446; accuracy: 0.924000\n",
            "epochs: 933; loss: 0.288226; accuracy: 0.924000\n",
            "epochs: 934; loss: 0.288233; accuracy: 0.924000\n",
            "epochs: 935; loss: 0.287841; accuracy: 0.925000\n",
            "epochs: 936; loss: 0.287740; accuracy: 0.922000\n",
            "epochs: 937; loss: 0.287597; accuracy: 0.924000\n",
            "epochs: 938; loss: 0.287396; accuracy: 0.923000\n",
            "epochs: 939; loss: 0.287221; accuracy: 0.924000\n",
            "epochs: 940; loss: 0.286767; accuracy: 0.923000\n",
            "epochs: 941; loss: 0.286484; accuracy: 0.924000\n",
            "epochs: 942; loss: 0.286389; accuracy: 0.924000\n",
            "epochs: 943; loss: 0.286118; accuracy: 0.924000\n",
            "epochs: 944; loss: 0.286121; accuracy: 0.924000\n",
            "epochs: 945; loss: 0.285855; accuracy: 0.924000\n",
            "epochs: 946; loss: 0.285491; accuracy: 0.924000\n",
            "epochs: 947; loss: 0.285345; accuracy: 0.924000\n",
            "epochs: 948; loss: 0.285153; accuracy: 0.924000\n",
            "epochs: 949; loss: 0.284908; accuracy: 0.924000\n",
            "epochs: 950; loss: 0.284737; accuracy: 0.923000\n",
            "epochs: 951; loss: 0.284445; accuracy: 0.925000\n",
            "epochs: 952; loss: 0.284225; accuracy: 0.923000\n",
            "epochs: 953; loss: 0.284065; accuracy: 0.924000\n",
            "epochs: 954; loss: 0.283966; accuracy: 0.924000\n",
            "epochs: 955; loss: 0.283643; accuracy: 0.923000\n",
            "epochs: 956; loss: 0.283376; accuracy: 0.924000\n",
            "epochs: 957; loss: 0.283003; accuracy: 0.924000\n",
            "epochs: 958; loss: 0.283149; accuracy: 0.923000\n",
            "epochs: 959; loss: 0.282846; accuracy: 0.925000\n",
            "epochs: 960; loss: 0.282691; accuracy: 0.924000\n",
            "epochs: 961; loss: 0.282469; accuracy: 0.924000\n",
            "epochs: 962; loss: 0.281920; accuracy: 0.924000\n",
            "epochs: 963; loss: 0.281848; accuracy: 0.924000\n",
            "epochs: 964; loss: 0.281843; accuracy: 0.924000\n",
            "epochs: 965; loss: 0.281621; accuracy: 0.924000\n",
            "epochs: 966; loss: 0.281357; accuracy: 0.923000\n",
            "epochs: 967; loss: 0.281039; accuracy: 0.923000\n",
            "epochs: 968; loss: 0.280915; accuracy: 0.924000\n",
            "epochs: 969; loss: 0.280691; accuracy: 0.925000\n",
            "epochs: 970; loss: 0.280541; accuracy: 0.923000\n",
            "epochs: 971; loss: 0.280360; accuracy: 0.924000\n",
            "epochs: 972; loss: 0.280242; accuracy: 0.924000\n",
            "epochs: 973; loss: 0.280021; accuracy: 0.924000\n",
            "epochs: 974; loss: 0.279671; accuracy: 0.925000\n",
            "epochs: 975; loss: 0.279365; accuracy: 0.924000\n",
            "epochs: 976; loss: 0.279287; accuracy: 0.924000\n",
            "epochs: 977; loss: 0.279143; accuracy: 0.924000\n",
            "epochs: 978; loss: 0.279005; accuracy: 0.924000\n",
            "epochs: 979; loss: 0.278710; accuracy: 0.925000\n",
            "epochs: 980; loss: 0.278410; accuracy: 0.923000\n",
            "epochs: 981; loss: 0.278371; accuracy: 0.926000\n",
            "epochs: 982; loss: 0.277872; accuracy: 0.926000\n",
            "epochs: 983; loss: 0.277964; accuracy: 0.925000\n",
            "epochs: 984; loss: 0.277734; accuracy: 0.925000\n",
            "epochs: 985; loss: 0.277462; accuracy: 0.926000\n",
            "epochs: 986; loss: 0.277383; accuracy: 0.923000\n",
            "epochs: 987; loss: 0.277082; accuracy: 0.923000\n",
            "epochs: 988; loss: 0.276881; accuracy: 0.927000\n",
            "epochs: 989; loss: 0.276700; accuracy: 0.924000\n",
            "epochs: 990; loss: 0.276341; accuracy: 0.927000\n",
            "epochs: 991; loss: 0.276406; accuracy: 0.927000\n",
            "epochs: 992; loss: 0.276106; accuracy: 0.925000\n",
            "epochs: 993; loss: 0.275841; accuracy: 0.924000\n",
            "epochs: 994; loss: 0.275673; accuracy: 0.925000\n",
            "epochs: 995; loss: 0.275559; accuracy: 0.924000\n",
            "epochs: 996; loss: 0.275394; accuracy: 0.927000\n",
            "epochs: 997; loss: 0.274964; accuracy: 0.927000\n",
            "epochs: 998; loss: 0.274936; accuracy: 0.925000\n",
            "epochs: 999; loss: 0.274717; accuracy: 0.927000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV9Z3/8dcnO1lIQhIWEwJBUhFRQSNurWOttKgtWq2tts5PW1tmfi61tY8ZtdOq47S/2uneKV0ca7V1Yazd0DJStVq1bgQXVoHIesMWyEbInnx+f9xLvIRgLnCTm3vv+/l45ME953y593NyyJuT7znn+zV3R0RE4l9KrAsQEZHoUKCLiCQIBbqISIJQoIuIJAgFuohIgkiL1QcXFxf75MmTY/XxIiJxadmyZbvdvWSgbTEL9MmTJ1NdXR2rjxcRiUtmtvlQ29TlIiKSIBToIiIJQoEuIpIgYtaHPpCuri4CgQDt7e2xLiXuZGVlUVZWRnp6eqxLEZEYGVGBHggEyMvLY/LkyZhZrMuJG+7Onj17CAQCVFRUxLocEYmREdXl0t7eTlFRkcL8MJkZRUVF+s1GJMmNqEAHFOZHSN83ERlRXS4iIvHC3TGzvj/3r9tvX2cPa3c0A/DAS5v5yAnj2dfRzUOvbuYHn5rJlJLcqNekQA/T2NjIww8/zHXXXXfYf/fCCy/k4YcfpqCgYAgqE5Foc3fau3r5l8fe4vMfmMLvlgV45LUtnDyxgJLcTJraukhPS2FbYxs1u1pISzFmlOaTmmIs29xwwHudPLGAVIPXtzQCMG50JjubOw5os+itbX2vqzc3KNCHWmNjIz/96U8HDPTu7m7S0g797Vq8ePFQliYiR6C31+lx58Wa3exqbuesY4tZWdvElvpWvvW/b/e1e2L59r7X/cN6v+5exwyy0t/tqc7OSKW1s4dR6Sms2hY8G68oziErPZWdzR1MLspm055WAKomFdLR3ctnTi/n8lPLhmJ3Fejhbr31Vt555x1mzpzJnDlzuOiii/j6179OYWEhb7/9NuvWreOSSy5h69attLe3c9NNNzF//nzg3aEMWlpauOCCC3j/+9/PSy+9RGlpKX/6058YNWrUAZ/1+OOP841vfIPOzk6Kiop46KGHGDduHC0tLdx4441UV1djZtxxxx1cdtllPPnkk3z1q1+lp6eH4uJinnnmmVh8i0SGXG+vk5Jifa+b2rpYta2ZjLQUunt6WbqpgfxRaRxTMIqNu/eRmmJ09vTyxpZGJhZm097dw7bGNto6e3h1Y/2gnzdzYgHtXT3kZaVx3Qen8tbWRiYVZTOpKIcx2RlMKsom0NDGxDHZQ73rR81iNQVdVVWV9x/LZc2aNRx//PEA/Pvjq1gd+h8vWqYfM5o7PnbCIbdv2rSJj370o6xcuRKA5557josuuoiVK1f23Q5YX1/PmDFjaGtr47TTTuNvf/sbRUVFBwT61KlTqa6uZubMmXzyk59k3rx5XHXVVQd8VkNDAwUFBZgZ9957L2vWrOF73/set9xyCx0dHfzwhz/sa9fd3c0pp5zC888/T0VFRV8N/YV//0RGupff2cNfVu9g2eYG6vd1csfHTuDvNbu5/6VNR/ye6alGemoKrZ09feuKczOZkJ/FitominMzmTY+j4279/HA505j6ti8KOzJ8DKzZe5eNdC2iM7QzWwu8CMgFbjX3e/ut30ScB9QAtQDV7l74KiqHiFmz559wL3dP/7xj/nDH/4AwNatW1m/fj1FRUUH/J2KigpmzpwJwKmnnsqmTZsOet9AIMCnPvUptm/fTmdnZ99nPP300yxcuLCvXWFhIY8//jjnnHNOX5uBwlwkGl7f0sDUsbmMzkrnra2NHDs2l9zMd2PC3enuddJTU6jZtZcUM6aU5LK3vYuMtGBXRFpKCtWb6lm8YjtnHlvM3vbgGfbK2ibaunrY2dxBVnoKgYa2Az77C78eeLC+Y0tyqCjOZc32ZsbnZ9HQ2slnz5rMrPJCahvbCDS0MX3CaKaU5DA2LxMzo7m9i9aOHsbnZw3dN2sEGjTQzSwVWADMAQLAUjNb5O6rw5p9F/i1uz9gZucB3wL+8WgKe68z6eGUk5PT9/q5557j6aef5uWXXyY7O5tzzz13wHu/MzMz+16npqbS1tZ2UJsbb7yRm2++mXnz5vHcc89x5513Dkn9ktw6unvo7nHau3owMzLSUli3cy/LNjXQ2dPLhrp9LF6xnYy0FCbkZ/H2jr0AjMnJoH5fJxDs+01NMer2drBh9z4ACrLTaWztGvTzH3j5kAMDAsH+6AtmTKC0YBTlRdmcOaWIiWOyeW1jPeVjshmVkcrorLRD3pY7ozR/wPWjs9IZnZV8T01HcoY+G6hx9w0AZrYQuBgID/TpwM2h188Cf4xmkcMlLy+PvXv3HnJ7U1MThYWFZGdn8/bbb/PKK68c8Wc1NTVRWloKwAMPPNC3fs6cOSxYsOCALpczzjiD6667jo0bN75nl4skj2WbG5hakkteVhpvbG1gV3MHxXmZ3P/3TThOZ3cvG3bvY0Pdvojer62rh8LsdwOwOPfdQH99SwO9/XpmpxTn9N3R8YHKYrY1tpGXlY4DRTkZPL+ujsnFOZQVjmJfRzcfOWE8J5bm09rZQ352OplpKVSOzes7q+9vdoX+fR+JSAK9FNgathwATu/X5i3gUoLdMh8H8sysyN33hDcys/nAfIDy8vIjrXnIFBUVcfbZZzNjxgwuuOACLrroogO2z507l5///Occf/zxHHfccZxxxhlH/Fl33nknl19+OYWFhZx33nls3LgRgK997Wtcf/31zJgxg9TUVO644w4uvfRS7rnnHi699FJ6e3sZO3YsTz311FHtq8RGS0c3aSlGc+hCX0+v8/qWBprbu2ho7eLU8kIaWzvZUt/KtsZ20lKNrPRUmtq6mDmxgF++uJFJRdlsDt05Ef46XGZaCh3dvX3Ln6wqY3tTOyW5mcyuGEN6agq79nZQlJNBZnoKMycWMKko56D32dfRTU5Yl0v/ZRlZBr0oamafAOa6++dDy/8InO7uN4S1OQb4CVABPA9cBsxw98ZDve9gF0Xl8On7FzvN7V3kZqSxbEsDf16+nX/6hyn8vWYPa3c0s3RTA29uffdHwQwGuxdhbF4me/Z10tPrB4XzflnpKeSPSmdncwcfOWEcE/JHccqkQmZPHkNhTjopFrxAKInlaC+K1gITw5bLQuv6uPs2gmfomFkucNl7hblIvGjp6GZncztdPb2kpRiZaam8vqWBiuIcUlOM59ft5v6XNh70EMlAd2pMKc5hw+59nFxWQGF2OlvqW/n4rFJ2Nndw6qRCdu1tpzA7g2MKRnHWsUV0dPeSYkaKQWdPL/s6ehg9Ko3MtNRh2nuJN5EE+lKg0swqCAb5FcCnwxuYWTFQ7+69wG0E73gRiUvdPb38ecV2nn17F48v305P/w7kfrLSU8jJSKVyXB7vG5fL+l0tTC4K3nFx5exyzCAtNYXSglHv+T4Hv++7wZ2WmkJ2hro65L0N+i/E3bvN7AZgCcHbFu9z91VmdhdQ7e6LgHOBb5mZE+xyuf5ICwofF0EiF6vnCRLFytomfvTMejbu3kfNrpa+9dPG55GXlcYls0pZEWjCzJg1sYDRo4I/OoXZGcwqLzzkxT2R4RTRf/nuvhhY3G/d7WGvHwMeO9pisrKy2LNnj4bQPUz7x0PPykque26PVFNrFy9v2M0Ty7dTvamBHc3v3npakpdJcW4Gu1s6+dzZFdz+senv/sX+twKIjDAj6ne4srIyAoEAdXV1sS4l7uyfsUiCj4tvrm+ltGAUm/bso7vHeWxZgD+9Wcue0K14/X2gspj//MRJTMg/vG4RkZFkRAV6enq6ZtyRI9bb63z/qXX85NmaQdumphh//uL7yUpLZVJRtn4jlIQwogJd5HC4O2/v2MuUkhx+9PR6fvrcOwe1mTo2l+kTRtPa2c1NH3ofM0pHK7wlYSnQJa64O9ua2mnY18lH/+vFg7b/x8Un8JnTJ/WN1ieSTBToMqJtb2rjkVe3sLm+lcLsDB55bctBD9mMH53FJbNKmTtjPDMnaoIRSV4KdBlR1u/cy69e2kReZhrN7V088trWAdulphi3zD2O+eccO8wVioxcCnQZEZ5cuZ1/fvD1AbddMGM8/+fMyRTmpJObmUZZ4cifaEAkFhToEhO9vU5Hdy9pqcatv1vB714PDp9/wjGj+fD08UwqymbujPE0t3cxNk/314tEQoEuw6qrp5ffVgf46h9WHLB+2vg87r7sJE4qzT/ggmb44+8i8t4U6DJsHnhpE3csWjXgtt9fd5bGKhE5SvoJkiG3fude5v9mGRtDs92cPbWIH3xqJmOyM+jsCY4oqDNxkaOnQJchdfbdf6W28d0p+O782HSuPmty38M9aRqvWyRqFOgSNW9saWBHU3CgqzsfX0X5mOy+ML/2/RVcdNIETikvjGWJIglNgS5HJdDQyv998HVOKsvnoVe3HLBtZ3MHU0py+MEnZ3KyHvgRGXIKdDliD76yma/9cSUAK2qb+tafXJbPW4EmvnR+JTd9qFJjp4gMk4gC3czmEpwAOhW4193v7re9HHgAKAi1uTU0hrokqOpN9Xzzz2uA4Azx377sJM48tkh3qojE0KA/fWaWCiwA5gABYKmZLXL31WHNvgY86u4/M7PpBCfDmDwE9coI8PTqnXxx4RuMHZ3Jw18447CnVhORoRHJLQazgRp33+DuncBC4OJ+bRwYHXqdD2yLXokyknT19PLtJ9+mtbOHX15dpTAXGUEi+f24FAgfISnAwZNx3Qn8xcxuBHKA8wd6IzObD8wHKC8vP9xaJcZeXL+bf35wGS0d3dx96YlMHZsX65JEJEy0bgK+Erjf3cuAC4HfmNlB7+3u97h7lbtXlZSUROmjZTj85K/rueqXr9LS0U1GagqXnqLp7kRGmkgCvRaYGLZcFloX7lrgUQB3fxnIAoqjUaDEXm1jG997ah0QnHtz2dfP1yz3IiNQJF0uS4FKM6sgGORXAJ/u12YL8CHgfjM7nmCga6bnBODu/G1tHe6w5EvncNx4dbOIjFSDBrq7d5vZDcASgrck3ufuq8zsLqDa3RcBXwH+28y+TPAC6TXu7kNZuAyPX764kW/8eQ1pKcbUsbmxLkdE3kNENw2H7ilf3G/d7WGvVwNnR7c0GQm+EbrX/JqzJpOqeTpFRjR1hMoh/fGN4KWS848fy7/OnRbjakRkMAp0GdCGuhZu+d1yTp1UyILPnKKLoCJxQM9py0EeXbqVf/3dcgC+fdlJZKZprHKReKBAlwPc9vvlPPLaVtJTjePG5+lCqEgcUaBLnwXP1vDIa8GHgpd9fQ55mfrnIRJP9BMrdHb38vCrm/nOkrUU52by3L+cS67CXCTu6Kc2ya3buZdP/eJlGlq7APjJp2cpzEXilH5yk9iuve18+AfPA/Ddy0/mwhPHazxzkTimn94ktujN4CjHN543lU+cqsG2ROKdbi5OUnV7O/j53zYwbXweX/nwcbEuR0SiQGfoSerT//0Ku1s6uPfqqliXIiJRojP0JPTQq5tZv6uFT1VNZObEgliXIyJRokBPMk1tXfzbH1YC8G8fPT7G1YhINCnQk0z1pnoALp1Vyuis9BhXIyLRpEBPMt9/ah3H5GfxzY+fGOtSRCTKFOhJ5Jk1O1m1rZlrPzCFURkacEsk0UQU6GY218zWmlmNmd06wPYfmNmboa91ZtYY/VLlaD22LADAR04YF+NKRGQoDHrbopmlAguAOUAAWGpmi0KzFAHg7l8Oa38jMGsIapWj8NrGev6yeidXzp5IWWF2rMsRkSEQyRn6bKDG3Te4eyewELj4PdpfCTwSjeIkOvZ1dPOFX1eTlZbCFz9UGetyRGSIRBLopcDWsOVAaN1BzGwSUAH89RDb55tZtZlV19XVHW6tcgR+/3qAE+5YQlNbFz+76lQm5I+KdUkiMkSifVH0CuAxd+8ZaKO73+PuVe5eVVJSEuWPlv52t3Rw86NvAXD9B4/l/VOLY1yRiAylSB79rwUmhi2XhdYN5Arg+qMtSo7ext37+O6StQDc/9nTOPe4sTGuSESGWiSBvhSoNLMKgkF+BfDp/o3MbBpQCLwc1QrlsDW3d/HB7z4HwKWnlCrMRZLEoF0u7t4N3AAsAdYAj7r7KjO7y8zmhTW9Aljo7j40pUqkVgSaADh1UiHfu/zkGFcjIsMlotEW3X0xsLjfutv7Ld8ZvbLkaPzxjVqyM1J54HOzMbNYlyMiw0RPiiaYh1/dwm+XBfj4rFJNJSeSZBToCaRhXydf/cMKAK46Y1KMqxGR4aZATyCvhUZSPG/aWI6fMDrG1YjIcFOgJwh352fPvUNuZhoLPn1KrMsRkRhQJ2scc3daO3tYWdvEPz24jMbWLu742HSNpCiSpBTocezeFzbyzcVrqBybS2NrF6Oz0rj6zMmxLktEYkSBHqfcnR8+vQ6A9btauOyUMm48byopKbpNUSRZKdDj0PamNn78zHr2dQaHzCktGMWN501lcnFOjCsTkVhSoMeZ3l7nzG+9O5jlQ58/nbOOLdIDRCKiQI8nXT29VH3j6b7lW+ZO42yNoCgiIQr0OLFlTysf/a8XaG7vBuBHV8zk4pkDDksvIklKgR4H2rt6+Oz9r9Hc3s208Xn8+trZjM3LinVZIjLCKNBHsL3tXfxuWYD/fmEjtY1t3HdNFedN0wTPIjIwBfoRcnd2t3Ty4CubWbUtOFztrPJC7n9pE7ddMI2Pzyo97AuV7k715gZ+8/Jmlm1uoLaxrW/bWccWKcxF5D0p0CPk7qyobeKksgI21LXwvafW8efl2w9o8/SaXQDc/OhbdHb3AlA5LpdZEwsxY8CA3z98vJmx4NkavvuXdQdsv/SUUv7xjEm8b1zeUOyWiCSQiALdzOYCPwJSgXvd/e4B2nwSuBNw4C13P2hWo3h286Nv8Yc3Bp557+dXncrvXw/wl9U7+9bd+vsVB7XLy0pj8Rc/wLjRWaze3kxPby+ff6CaguwMOrt7+87Iv3HJDM48togJ+VlkZ+j/XBGJjA02wZCZpQLrgDlAgOCUdFe6++qwNpXAo8B57t5gZmPdfdd7vW9VVZVXV1cfbf1DLtDQyr0vbOT+lzb1rRudlcZ508Zy+8dOYExORt/6nl6nsbWTF2t2c9+LG+l1WFHbdNB7lo/JZkt960Hrr//gsVx37lRyNI65iByCmS1z96qBtkWSHLOBGnffEHqzhcDFwOqwNl8AFrh7A8BgYR5PfvPyZu5/aRPH5Gfxq8/O5rjxh+76SE0xinIzuXhmad8thY2tnXxnyVpOmzyGtTv3svC1LbR2dvf9nVMnFfLVC4+nfEw2JXmZQ74/IpK4Ign0UmBr2HIAOL1fm/cBmNnfCXbL3OnuT0alwhjZ3dLB3B++wO6WDqaNz+PJL51zRO9TkJ3BNz9+Yt/yLXOnAdDS0U1HVw9FuQpxEYmOaP1unwZUAucCZcDzZnaiuzeGNzKz+cB8gPLy8ih99NA4/f89Q09vsDvqW5eeOEjrw5ebmaYp4kQkqiKZ4KIWmBi2XBZaFy4ALHL3LnffSLDPvbL/G7n7Pe5e5e5VJSUlR1rzkFu2uYGeXmdKSQ6b7r6IWeWFsS5JRGRQkQT6UqDSzCrMLAO4AljUr80fCZ6dY2bFBLtgNkSxzmH102drKMxO59F/OjPWpYiIRGzQQHf3buAGYAmwBnjU3VeZ2V1mNi/UbAmwx8xWA88C/+Lue4aq6KG0p6WD59bV8cnTJlKs/m0RiSMRdeK6+2Jgcb91t4e9duDm0FfccndufvQtenqdSzTwlYjEGU0SHeaXL27kb+vqOPe4Eo6fMDrW5YiIHBYFekhvr3P3/74NwH9cPCPG1YiIHD4FOvu7Wt6ku9f57uUnM3FMdqxLEhE5bLoRGrjxkTd4IjTQ1kdO0IiGIhKfkj7Q97R08MTy7XygsphfXXMaaan6pUVE4lPSp9cdi1YB8KXz36cwF5G4ltQJtq2xjSeWb6e0YBSnlBfEuhwRkaOS1IG+ZNUOAO6cd8Jhzy4kIjLSJHWgP71mJxXFOcyZrguhIhL/kjbQt9a38tI7e/jYycfEuhQRkahI2kD/98dXk5WWyhWnTRy8sYhIHEjKQH9hfR1Pr9nJl+dUckzBqFiXIyISFUkZ6M+vqyMjLYVrzqqIdSkiIlGTlIH+6sZ6TizNJyMtKXdfRBJU0iXajqZ2lgea+NDxY2NdiohIVCVdoD+1ZicAH9atiiKSYCIKdDOba2ZrzazGzG4dYPs1ZlZnZm+Gvj4f/VKPXntXD/e+sIHjxuVxbElurMsREYmqQQfnMrNUYAEwh+Bk0EvNbJG7r+7X9H/c/YYhqDFqHnxlM5v3tPLgtafryVARSTiRnKHPBmrcfYO7dwILgYuHtqyh8fI7e5g6Npf3VxbHuhQRkaiLJNBLga1hy4HQuv4uM7PlZvaYmQ34tI6ZzTezajOrrqurO4Jyj87y2iZOKssf9s8VERkO0boo+jgw2d1PAp4CHhiokbvf4+5V7l5VUlISpY+OzK7mdur2dnBiqQJdRBJTJIFeC4SfcZeF1vVx9z3u3hFavBc4NTrlRc/KbU0AzFCgi0iCiiTQlwKVZlZhZhnAFcCi8AZmNiFscR6wJnolRseKQDNmcPyE0bEuRURkSAx6l4u7d5vZDcASIBW4z91XmdldQLW7LwK+aGbzgG6gHrhmCGs+Iitqm6goziE3M+ln3RORBBVRurn7YmBxv3W3h72+DbgtuqVFT1dPLy+/s5t5MzVUrogkrqR4UnTznn3s6+zhtMljYl2KiMiQSYpAr9nVAqCnQ0UkoSVFoC/b3EBGagrHjc+LdSkiIkMmKQL9lQ31zCwvICs9NdaliIgMmYQP9LU79rKitolz9Li/iCS4hA/0ZZsbALh45kCjFYiIJI6ED/R1O/eSnZFKqeYOFZEEl/CBXrOrhaljc0lJ0XC5IpLYEj7Q1+/aS+VY3d0iIokvoQO9qa2Lnc0dVI7T/ecikvgSOtD3P1BUOVaBLiKJL6EDff3OvQDqchGRpJDQgf72jr2MSk+lrFB3uIhI4kvoQF+9rZnjJ+TpDhcRSQoJG+i9vc7q7c2ccIxmKBKR5JCwgb69uZ2Wjm6mTVD/uYgkh4gC3czmmtlaM6sxs1vfo91lZuZmVhW9Eo/MjqY2AI7RE6IikiQGDXQzSwUWABcA04ErzWz6AO3ygJuAV6Nd5JHY0RScs3pCflaMKxERGR6RnKHPBmrcfYO7dwILgYsHaPcfwLeB9ijWd8S2h87Qx49WoItIcogk0EuBrWHLgdC6PmZ2CjDR3f/8Xm9kZvPNrNrMquvq6g672MOxo6mdrPQU8kelD+nniIiMFEd9UdTMUoDvA18ZrK273+PuVe5eVVJScrQf/Z62N7czIX8UZrplUUSSQySBXgtMDFsuC63bLw+YATxnZpuAM4BFsbww2tbZwwvr6jixVLcsikjyiCTQlwKVZlZhZhnAFcCi/Rvdvcndi919srtPBl4B5rl79ZBUHIHn19fR3N7NFadNHLyxiEiCGDTQ3b0buAFYAqwBHnX3VWZ2l5nNG+oCj8SGun0AnFimM3QRSR5pkTRy98XA4n7rbj9E23OPvqyjs6V+H0U5GeRl6YKoiCSPhHxSdPOeVsqLsmNdhojIsErYQJ9clBPrMkREhlXCBXpTaxe1jW2apUhEkk7CBfry2kYATi4riHElIiLDK/ECPdAEwAzdgy4iSSbhAr22sY3i3Aw98i8iSSfhAn333g6KczNjXYaIyLBLvEBv6aAoNyPWZYiIDLuEC/RAQxvjNGSuiCShhAr0nc3t7NrboUG5RCQpJVSg7x/DpXKs5hEVkeSTUIG+taEVgIljNI+oiCSfhAr0QH0rKaaJoUUkOSVUoG+pb2VC/ijSUxNqt0REIpJQybe1oU3dLSKStCIKdDOba2ZrzazGzG4dYPs/m9kKM3vTzF40s+nRL3VwW+tbmVioYXNFJDkNGuhmlgosAC4ApgNXDhDYD7v7ie4+E/hPgpNGD6v2rh527e2gfIwCXUSSUyRn6LOBGnff4O6dwELg4vAG7t4ctpgDePRKjEyg7w4XBbqIJKdIpqArBbaGLQeA0/s3MrPrgZuBDOC8gd7IzOYD8wHKy8sPt9b3tLW+DdAtiyKSvKJ2UdTdF7j7scAtwNcO0eYed69y96qSkpJofTQA79S1AGimIhFJWpEEei0wMWy5LLTuUBYClxxNUUdi7Y69FOdmUqSRFkUkSUUS6EuBSjOrMLMM4ApgUXgDM6sMW7wIWB+9EiOzvald3S0iktQG7UN3924zuwFYAqQC97n7KjO7C6h290XADWZ2PtAFNABXD2XRA9nd0qELoiKS1CK5KIq7LwYW91t3e9jrm6Jc12Hb3dLBrHLNIyoiySshnhTt6umlfl8nJeo/F5EklhCBvqOpnV6HMj0lKiJJLCECff+wuaWFuigqIskrIQI90BB8qKhMgS4iSSxhAt0MJuQr0EUkeSVEoL9T18Ix+aPISEuI3REROSIJkYAra5s4qUwTQ4tIcov7QO/u6SXQ0MaUEo3hIiLJLe4DfUdzOz29rlsWRSTpxX2gb29qBzQxtIhI3Af6zuZgoI8fnRXjSkREYivuA31H6Ax93Gg99i8iyS3uA33X3g4y01LIH5Ue61JERGIq7gN9Z3M740ZnYWaxLkVEJKbiPtB3NLWr/1xEhAQI9EBDmwblEhEhwkA3s7lmttbMaszs1gG232xmq81suZk9Y2aTol/qwVo7u6ltbONYPVQkIjJ4oJtZKrAAuACYDlxpZtP7NXsDqHL3k4DHgP+MdqED2VofHGVxUpECXUQkkjP02UCNu29w905gIXBxeAN3f9bdW0OLrwBl0S1zYIHQOOgaNldEJLJALwW2hi0HQusO5VrgfwfaYGbzzazazKrr6uoir/IQ9o+Drj50EZEoXxQ1s6uAKuA7A21393vcvcrdq0pKSo768wINrWSmpWguURERIC2CNrXAxLDlstC6A5jZ+cC/Af/g7h3RKe+97b/DRfegi4hEdoa+FKg0s7tDL6UAAAZvSURBVAozywCuABaFNzCzWcAvgHnuviv6ZQ6strGNUg3KJSICRBDo7t4N3AAsAdYAj7r7KjO7y8zmhZp9B8gFfmtmb5rZokO8XVQFGto0bK6ISEgkXS64+2Jgcb91t4e9Pj/KdQ2qtbOb+n2dusNFRCQkbp8UrQ3d4aJAFxEJittADyjQRUQOEMeBvv+hIvWhi4hAPAd6YxsZqboHXURkv7gN9Le2NlJRnENKiu5BFxGBOA30HU3tvLqxngtOHB/rUkRERoy4DPSVtU24wznvO/rhA0REEkVcBvr25uDE0HpKVETkXXEZ6Nsa20hLMYp1QVREpE9cBvr6nS1UFOeQqguiIiJ94i7Q3Z1V25qYNmF0rEsRERlR4i7Qt9a3sb2pndmTC2NdiojIiBJ3gf7Kxj0AnD6lKMaViIiMLHEX6IXZGXx4+jgqx+bGuhQRkRElouFzR5I508cxZ/q4WJchIjLiRHSGbmZzzWytmdWY2a0DbD/HzF43s24z+0T0yxQRkcEMGuhmlgosAC4ApgNXmtn0fs22ANcAD0e7QBERiUwkXS6zgRp33wBgZguBi4HV+xu4+6bQtt4hqFFERCIQSZdLKbA1bDkQWiciIiPIsN7lYmbzzazazKrr6uqG86NFRBJeJIFeC0wMWy4LrTts7n6Pu1e5e1VJiUZKFBGJpkgCfSlQaWYVZpYBXAEsGtqyRETkcA0a6O7eDdwALAHWAI+6+yozu8vM5gGY2WlmFgAuB35hZquGsmgRETmYuXtsPtisDth8hH+9GNgdxXLigfY5OWifk8PR7PMkdx+wzzpmgX40zKza3atiXcdw0j4nB+1zchiqfY67sVxERGRgCnQRkQQRr4F+T6wLiAHtc3LQPieHIdnnuOxDFxGRg8XrGbqIiPSjQBcRSRBxF+iDjc0er8xsopk9a2arzWyVmd0UWj/GzJ4ys/WhPwtD683Mfhz6Piw3s1NiuwdHxsxSzewNM3sitFxhZq+G9ut/Qk8nY2aZoeWa0PbJsaz7SJlZgZk9ZmZvm9kaMzszCY7xl0P/plea2SNmlpWIx9nM7jOzXWa2MmzdYR9bM7s61H69mV19ODXEVaBHODZ7vOoGvuLu04EzgOtD+3Yr8Iy7VwLPhJYh+D2oDH3NB342/CVHxU0En0De79vAD9x9KtAAXBtafy3QEFr/g1C7ePQj4El3nwacTHDfE/YYm1kp8EWgyt1nAKkEhw9JxON8PzC337rDOrZmNga4Azid4NDld+z/TyAi7h43X8CZwJKw5duA22Jd1xDt65+AOcBaYEJo3QRgbej1L4Arw9r3tYuXL4IDvT0DnAc8ARjBp+fS+h9vgkNPnBl6nRZqZ7Heh8Pc33xgY/+6E/wY7x9+e0zouD0BfCRRjzMwGVh5pMcWuBL4Rdj6A9oN9hVXZ+gkydjsoV8zZwGvAuPcfXto0w5g/4SqifC9+CHwr8D+iVGKgEYPjh8EB+5T3/6GtjeF2seTCqAO+FWom+leM8shgY+xu9cC3yU4q9l2gsdtGYl9nMMd7rE9qmMeb4Ge8MwsF/gd8CV3bw7f5sH/shPiPlMz+yiwy92XxbqWYZQGnAL8zN1nAft491dwILGOMUCou+Bigv+ZHQPkcHC3RFIYjmMbb4EetbHZRyIzSycY5g+5++9Dq3ea2YTQ9gnArtD6eP9enA3MM7NNwEKC3S4/AgrMbP/UiOH71Le/oe35wJ7hLDgKAkDA3V8NLT9GMOAT9RgDnA9sdPc6d+8Cfk/w2CfycQ53uMf2qI55vAV6wo7NbmYG/BJY4+7fD9u0CNh/pftqgn3r+9f/n9DV8jOAprBf7UY8d7/N3cvcfTLB4/hXd/8M8CzwiVCz/vu7//vwiVD7uDqTdfcdwFYzOy606kME5+ZNyGMcsgU4w8yyQ//G9+9zwh7nfg732C4BPmxmhaHfbj4cWheZWF9EOIKLDhcC64B3gH+LdT1R3K/3E/x1bDnwZujrQoL9h88A64GngTGh9kbwjp93gBUE7yKI+X4c4b6fCzwRej0FeA2oAX4LZIbWZ4WWa0Lbp8S67iPc15lAdeg4/xEoTPRjDPw78DawEvgNkJmIxxl4hOB1gi6Cv41deyTHFvhcaP9rgM8eTg169F9EJEHEW5eLiIgcggJdRCRBKNBFRBKEAl1EJEEo0EVEEoQCXUQkQSjQRUQSxP8HnY22Njp+xLcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}