{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khg5OLq5ico3"
      },
      "source": [
        "## **협업 필터링 (CF)**\n",
        "\n",
        "어떤 아이템에 대해서 비슷한 취향을 가진 사람들은 다른 아이템에 대해서도 비슷한 취향을 가지고 있을 것이라고 가정해 볼 수 있다. 이러한 아이디어로 만들어진 추천 알고리즘이 협업 필터링(Collaborative Filtering)이라고 한다.\n",
        "\n",
        "### **유사도 지표**\n",
        "* **상관계수** : 연속된 값에 적용할 수 있는 가장 기본적인 유사도 지표로는 상관계수(correlation coefficient)가 있다. 상관계수는 이해하기 쉬운 유사도 측정치이기는 하지만 협업 필터링에서 사용하는 경우, 늘 좋은 결과를 가져오지는 못하는 것으로 알려져 있다.\n",
        "\n",
        "* **코사인 유사도** : 코사인 유사도에서는 각 아이템을 하나의 차원으로 보고 사용자의 평가값을 좌표값으로 본다. 그렇게 되면 각 사용자의 평가값을 벡터로 해서, 두 사용자 간의 벡터의 각도(코사인 값)를 구할 수 있다.\n",
        "```python\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# ...\n",
        "user_similiarity = cosine_similarity(rating_matrix, rating_matrix)\n",
        "```\n",
        "\n",
        "* 만일 데이터가 이진값(binary)을 갖는다면 타니모토 계수(Tanimoto coefficient) 혹은, 자카드 계수(Jaccard coefficient) 등을 주로 사용한다.\n",
        "\n",
        "### **이웃을 고려한 CF**\n",
        "* CF 알고리즘을 개선할 수 있는 한 가지 방법은 사용자 중에서 유사도가 높은 사용자를 선정해서 이웃의 크기를 줄이는 것이다. 이렇게 대상 사용자의 유사도가 높은 사람의 평가만 사용하면 당연히 예측의 정확도가 올라갈 것으로 예상해 볼 수 있다.\n",
        "* 크게 두 가지 방법이 있는데, 하나는 이웃의 크기를 미리 정해높고 추천 대상 사용자와 가장 유사한 K명을 선택하는 KNN 방식과, 또 다른 하나는 특정 유사도의 기준을 정해놓고, 이 기준을 충족하는 모든 이웃을 선택하는 threshold 방식이 있다. 주로 전자를 사용한다.\n",
        "* 주로 CF 알고리즘의 정확도를 최대로 하는 이웃의 크기가 존재한다. 이웃의 크기를 너무 크게 하면 집단별 취향의 차이가 없어지고, best-seller 방식과 크게 다를 바가 없게 된다. 반대로, 이웃의 크기가 지나지체 작으면 유사도가 매우 높은 소수의 이웃의 평가만을 사용하게 된다. 이렇게 되면 소수의 평가에 지나치게 의존하게 되어 예측치의 신뢰성이 낮아지게 된다. \n",
        "\n",
        "### **사용자의 평가 경향을 고려한 CF**\n",
        "* CF의 정확도를 더 개선시키는 방법 중의 하나는 사용자의 평가 경향 (user_bias)을 고려해서 예측치를 조정하는 것이다. 사용자에 따라서 평가를 전체적으로 높게 하는 사람이 있는 반면에, 평가를 전체적으로 낮게 하는 사람이 있는 등, 사람에 따라 평가경향이 다르다. 이러한 평가 경향을 고려하기 위해 CF 알고리즘에 대입되는 데이터는 실제 평점이 아닌, 평점에서 평균을 뺀 평점 편차이다.\n",
        "```python\n",
        "rating_mean = rating_matrix.mean(axis = 1) # 각 사용자마다 평점 평균을 구한다.\n",
        "rating_bias = (rating_matrix.T - rating_mean).T # 평점에서 평균을 뺀 편차를 구한다.\n",
        "```\n",
        "\n",
        "### **신뢰도 가중**\n",
        "* CF의 정확도를 개선시키는 마지막 방법은 신뢰도 가중(significance weights)이 있다. A에 대해서 영화 평점을 예측할 때, A와 공통으로 평가한 영화의 수가 특정 수 이상인 사용자들만 CF 알고리즘에 활용하는 것이다. A와 공통으로 평가한 영화의 수가 많을 수록, 둘 사이의 유사도 지수의 신뢰도가 높다고 할 수 있으므로, 이러한 점을 반영한 것이다.\n",
        "```python\n",
        "no_rating = movie_ratings.isnull() # movie_id를 평점 매기지 않은 유저들\n",
        "common_counts = counts[user_id] \n",
        "low_significance = common_counts < SIG_LEVEL # 신뢰도가 일정 수준 미만인 유저들\n",
        "none_rating_idx = movie_ratings[no_rating | low_significance].index # 인덱스 추출\n",
        "movie_ratings = movie_ratings.drop(none_rating_idx)\n",
        "sim_scores = sim_scores.drop(none_rating_idx)\n",
        "```\n",
        "\n",
        "### **IBCF와 UBCF**\n",
        "* 이 코드에서는 사용자를 기준으로 비슷한 취양의 이웃을 선정하는 방식을 사용하였다. 이런 방식을 UBCF(User-Based CF)라고 한다. 반대로 아이템을 기준으로 하는 아이템 기반 CF(Item-Based CF)도 가능하다.\n",
        "* UBCF는 각 사용자 별로 맞춤형 추천을 하기 때문에 데이터가 풍부한 경우 정확한 추천이 가능하다. 반대로 IBCF는 정확도는 떨어지지만 사용자별로 따로 따로 계산을 하지 않기 때문에 계산이 빠르다는 장점이 있다. 또한 UBCF는 정확할 때에는 매우 정확하지만, 터무니 없는 경우도 상당히 있는 데 비해, IBCF는 그럴 위험이 적다.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpKXtISNidUo",
        "outputId": "c981fb73-74f4-4c34-d89e-13bef133c530"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "ratings = pd.read_csv('/content/u.data', names = r_cols, sep='\\t', encoding = 'latin-1')\n",
        "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)\n",
        "\n",
        "i_cols = ['movie_id', 'title', 'release date', 'video release date', 'IMDB URL', 'umknown', 'Action',\n",
        "          'Adventure', 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', \n",
        "          'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'war', 'western']\n",
        "movies = pd.read_csv('/content/u.item', sep='|', names = i_cols, encoding = 'latin-1')\n",
        "\n",
        "x = ratings.copy()\n",
        "y = ratings['user_id']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, stratify = y)\n",
        "\n",
        "# 사용자와 영화이름, 평점을 행렬 구조로 바꾼다.\n",
        "rating_matrix = x_train.pivot(index='user_id', columns='movie_id', values='rating')\n",
        "\n",
        "# RMSE 함수\n",
        "def RMSE(y_true, y_pred):\n",
        "  return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred)) ** 2))\n",
        "\n",
        "# CF 알고리즘의 손실값을 계산하는 함수\n",
        "def score(model, neighbor_size=0):\n",
        "  id_pairs = zip(x_test['user_id'], x_test['movie_id'])\n",
        "  y_pred = np.array([model(user, movie, neighbor_size) for (user, movie) in id_pairs])\n",
        "  y_true = np.array(x_test['rating'])\n",
        "  return RMSE(y_true, y_pred)\n",
        "\n",
        "# 사용자 간의 코사인 유사도를 계산한다.\n",
        "matrix_dummy = rating_matrix.copy().fillna(0)\n",
        "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
        "user_similarity = pd.DataFrame(user_similarity, index = matrix_dummy.index, columns = matrix_dummy.index)\n",
        "\n",
        "# 사용자의 평가 경향을 고려하기 위해 평균을 뺀다.\n",
        "rating_mean = rating_matrix.mean(axis = 1)\n",
        "rating_bias = (rating_matrix.T - rating_mean).T\n",
        "\n",
        "# 신뢰도 가중을 위해, 사용자 간에 공통으로 평가한 영화의 수를 계산한다.\n",
        "rating_binary1 = np.array((rating_matrix > 0).astype(float))\n",
        "rating_binary2 = rating_binary1.T\n",
        "counts = np.dot(rating_binary1, rating_binary2)\n",
        "counts = pd.DataFrame(counts, index = rating_matrix.index, columns = rating_matrix.index).fillna(0)\n",
        "\n",
        "def CF_knn_bias_sig(user_id, movie_id, neighbor_size):\n",
        "  if movie_id in rating_bias:\n",
        "    sim_scores = user_similarity[user_id].copy()\n",
        "    movie_ratings = rating_matrix[movie_id].copy()\n",
        "\n",
        "    no_rating = movie_ratings.isnull() # movie_id를 평점 매기지 않은 유저들\n",
        "    common_counts = counts[user_id] \n",
        "    low_significance = common_counts < SIG_LEVEL # 신뢰도가 일정 수준 미만인 유저들\n",
        "    none_rating_idx = movie_ratings[no_rating | low_significance].index # 인덱스 추출\n",
        "\n",
        "    movie_ratings = movie_ratings.drop(none_rating_idx)\n",
        "    sim_scores = sim_scores.drop(none_rating_idx)\n",
        "\n",
        "    if neighbor_size == 0:\n",
        "      prediction = np.dot(movie_ratings, sim_scores) / sim_scores.sum()\n",
        "      prediction = prediction + rating_mean[user_id]\n",
        "    else:\n",
        "      if len(sim_scores) > MIN_RATINGS:\n",
        "        neighbor_size = min(neighbor_size, len(sim_scores))\n",
        "        sim_scores = np.array(sim_scores)\n",
        "        movie_ratings = np.array(movie_ratings)\n",
        "        \n",
        "        user_idx = np.argsort(sim_scores) # 유사도 순으로 정렬\n",
        "        sim_scores = sim_scores[user_idx][-neighbor_size:]\n",
        "        movie_ratings = movie_ratings[user_idx][-neighbor_size:]\n",
        "        prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
        "        prediction = prediction + rating_mean[user_id]\n",
        "      else:\n",
        "        prediction = rating_mean[user_id]\n",
        "  else:\n",
        "    prediction = rating_mean[user_id]\n",
        "  \n",
        "  return prediction\n",
        "\n",
        "SIG_LEVEL = 3\n",
        "MIN_RATINGS = 2\n",
        "print(\"손실 값 : %d\" % score(CF_knn_bias_sig, 30))\n",
        "\n",
        "# 특정 유저에 대해서 n_items 개수의 영화를 추천해준다.\n",
        "def recom_movie(user_id, n_items, neighbor_size=30):\n",
        "  user_movie = rating_matrix.loc[user_id].copy()\n",
        "  for movie in rating_matrix:\n",
        "    if pd.notnull(user_movie.loc[movie]):\n",
        "      user_movie.loc[movie] = 0 # 이미 평점이 맺어진 영화는 값을 0으로 바꿔서 추천 후보에서 제외한다.\n",
        "    else:\n",
        "      user_movie.loc[movie] = CF_knn_bias_sig(user_id, movie, 30)\n",
        "\n",
        "  movie_sort = user_movie.sort_values(ascending=False)[:n_items] # 영화 평점순으로 정렬\n",
        "  recom_movies = movies.loc[movie_sort.index]\n",
        "  recommendations = recom_movies['title']\n",
        "  return recommendations\n",
        "\n",
        "print(recom_movie(user_id=2, n_items=5, neighbor_size=30))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "손실 값 : 3\n",
            "movie_id\n",
            "119                      Striptease (1996)\n",
            "1449                Golden Earrings (1947)\n",
            "64      What's Eating Gilbert Grape (1993)\n",
            "963            Month by the Lake, A (1995)\n",
            "187               Full Metal Jacket (1987)\n",
            "Name: title, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}